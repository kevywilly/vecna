{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:27:39.530599Z",
     "start_time": "2024-02-21T08:27:38.596852Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.kinematics import Kinematics, Vector3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "        for c in range (-90,90,10):\n",
    "            for f in range(-90,90,10):\n",
    "                for t in range(-90,90,10):\n",
    "                    x,y,z = Kinematics.forward(Vector3(c,f,t)).array()\n",
    "                    self.items.append([round(x,2), round(y,2), round(z,2), c/90.0, f/90.0, t/90.0])\n",
    "\n",
    "        self.items = np.array(self.items)\n",
    "        X = self.items[:,0:3]\n",
    "        Y = self.items[:,3:6]\n",
    "        self.maxs = np.max(X,0)\n",
    "        self.means = np.mean(X,0)\n",
    "        self.stds = np.std(X,0)\n",
    "        X = self.normalize(X, self.means, self.stds, self.maxs)\n",
    "        self.inputs = torch.from_numpy(X.astype(np.float32))\n",
    "        #self.inputs = torch.nn.functional.normalize(torch.from_numpy(X.astype(np.float32)),dim=0)\n",
    "        self.targets = torch.from_numpy(Y.astype(np.float32))\n",
    "\n",
    "        #X = (X-self.means)/self.stds\n",
    "        #self.X = torch.nn.functional.normalize(input=torch.from_numpy(X.astype(np.float32)))\n",
    "        # self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        # self.Y = torch.from_numpy(Y.astype(np.float32))\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(x, means, stds, maxs):\n",
    "        return (x/np.max(maxs))\n",
    "        #return (x-means)/stds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.inputs[idx].reshape(1,-1), self.targets[idx].reshape(1,-1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:27:39.537050Z",
     "start_time": "2024-02-21T08:27:39.535871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "test_percent = 0.2\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                     batch_size=100,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                     batch_size=100,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:27:39.566139Z",
     "start_time": "2024-02-21T08:27:39.563145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3,16),\n",
    "    nn.Linear(16,32),\n",
    "    nn.Linear(32,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,3)\n",
    ")\n",
    "\n",
    "best_model = '/Users/kevywilly/Projects/vecna/best_model.pth'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:27:39.569932Z",
     "start_time": "2024-02-21T08:27:39.568010Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "epochs = 1500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:27:40.003626Z",
     "start_time": "2024-02-21T08:27:39.570843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500, Train Loss: 0.2824,       Test Loss: 0.2032, Duration: 0:00:00.038119\n",
      "Epoch 2/1500, Train Loss: 0.1635,       Test Loss: 0.0970, Duration: 0:00:00.026576\n",
      "Epoch 3/1500, Train Loss: 0.0862,       Test Loss: 0.0786, Duration: 0:00:00.026291\n",
      "Epoch 4/1500, Train Loss: 0.0690,       Test Loss: 0.0582, Duration: 0:00:00.026167\n",
      "Epoch 5/1500, Train Loss: 0.0530,       Test Loss: 0.0454, Duration: 0:00:00.026450\n",
      "Epoch 6/1500, Train Loss: 0.0425,       Test Loss: 0.0411, Duration: 0:00:00.026136\n",
      "Epoch 7/1500, Train Loss: 0.0396,       Test Loss: 0.0390, Duration: 0:00:00.026069\n",
      "Epoch 8/1500, Train Loss: 0.0378,       Test Loss: 0.0374, Duration: 0:00:00.026623\n",
      "Epoch 9/1500, Train Loss: 0.0378,       Test Loss: 0.0380, Duration: 0:00:00.027548\n",
      "Epoch 10/1500, Train Loss: 0.0366,       Test Loss: 0.0366, Duration: 0:00:00.027212\n",
      "Epoch 11/1500, Train Loss: 0.0367,       Test Loss: 0.0352, Duration: 0:00:00.026364\n",
      "Epoch 12/1500, Train Loss: 0.0352,       Test Loss: 0.0348, Duration: 0:00:00.026263\n",
      "Epoch 13/1500, Train Loss: 0.0349,       Test Loss: 0.0354, Duration: 0:00:00.026507\n",
      "Epoch 14/1500, Train Loss: 0.0343,       Test Loss: 0.0339, Duration: 0:00:00.026318\n",
      "Epoch 15/1500, Train Loss: 0.0338,       Test Loss: 0.0337, Duration: 0:00:00.026132\n",
      "Epoch 16/1500, Train Loss: 0.0329,       Test Loss: 0.0326, Duration: 0:00:00.026179\n",
      "Epoch 17/1500, Train Loss: 0.0325,       Test Loss: 0.0351, Duration: 0:00:00.026497\n",
      "Epoch 18/1500, Train Loss: 0.0324,       Test Loss: 0.0337, Duration: 0:00:00.027223\n",
      "Epoch 19/1500, Train Loss: 0.0322,       Test Loss: 0.0337, Duration: 0:00:00.027102\n",
      "Epoch 20/1500, Train Loss: 0.0311,       Test Loss: 0.0308, Duration: 0:00:00.027091\n",
      "Epoch 21/1500, Train Loss: 0.0295,       Test Loss: 0.0298, Duration: 0:00:00.026836\n",
      "Epoch 22/1500, Train Loss: 0.0276,       Test Loss: 0.0264, Duration: 0:00:00.027040\n",
      "Epoch 23/1500, Train Loss: 0.0267,       Test Loss: 0.0270, Duration: 0:00:00.026745\n",
      "Epoch 24/1500, Train Loss: 0.0263,       Test Loss: 0.0265, Duration: 0:00:00.027160\n",
      "Epoch 25/1500, Train Loss: 0.0257,       Test Loss: 0.0262, Duration: 0:00:00.027403\n",
      "Epoch 26/1500, Train Loss: 0.0254,       Test Loss: 0.0263, Duration: 0:00:00.028276\n",
      "Epoch 27/1500, Train Loss: 0.0251,       Test Loss: 0.0235, Duration: 0:00:00.027888\n",
      "Epoch 28/1500, Train Loss: 0.0228,       Test Loss: 0.0231, Duration: 0:00:00.027060\n",
      "Epoch 29/1500, Train Loss: 0.0230,       Test Loss: 0.0220, Duration: 0:00:00.026996\n",
      "Epoch 30/1500, Train Loss: 0.0216,       Test Loss: 0.0223, Duration: 0:00:00.026959\n",
      "Epoch 31/1500, Train Loss: 0.0217,       Test Loss: 0.0199, Duration: 0:00:00.027146\n",
      "Epoch 32/1500, Train Loss: 0.0204,       Test Loss: 0.0199, Duration: 0:00:00.027048\n",
      "Epoch 33/1500, Train Loss: 0.0195,       Test Loss: 0.0181, Duration: 0:00:00.027703\n",
      "Epoch 34/1500, Train Loss: 0.0192,       Test Loss: 0.0193, Duration: 0:00:00.026924\n",
      "Epoch 35/1500, Train Loss: 0.0194,       Test Loss: 0.0177, Duration: 0:00:00.026851\n",
      "Epoch 36/1500, Train Loss: 0.0189,       Test Loss: 0.0179, Duration: 0:00:00.026243\n",
      "Epoch 37/1500, Train Loss: 0.0187,       Test Loss: 0.0165, Duration: 0:00:00.025735\n",
      "Epoch 38/1500, Train Loss: 0.0181,       Test Loss: 0.0177, Duration: 0:00:00.025590\n",
      "Epoch 39/1500, Train Loss: 0.0174,       Test Loss: 0.0164, Duration: 0:00:00.025455\n",
      "Epoch 40/1500, Train Loss: 0.0178,       Test Loss: 0.0176, Duration: 0:00:00.025871\n",
      "Epoch 41/1500, Train Loss: 0.0183,       Test Loss: 0.0183, Duration: 0:00:00.026755\n",
      "Epoch 42/1500, Train Loss: 0.0178,       Test Loss: 0.0172, Duration: 0:00:00.026493\n",
      "Epoch 43/1500, Train Loss: 0.0173,       Test Loss: 0.0168, Duration: 0:00:00.025779\n",
      "Epoch 44/1500, Train Loss: 0.0170,       Test Loss: 0.0161, Duration: 0:00:00.026806\n",
      "Epoch 45/1500, Train Loss: 0.0165,       Test Loss: 0.0162, Duration: 0:00:00.027075\n",
      "Epoch 46/1500, Train Loss: 0.0166,       Test Loss: 0.0177, Duration: 0:00:00.027728\n",
      "Epoch 47/1500, Train Loss: 0.0175,       Test Loss: 0.0187, Duration: 0:00:00.027227\n",
      "Epoch 48/1500, Train Loss: 0.0174,       Test Loss: 0.0193, Duration: 0:00:00.026073\n",
      "Epoch 49/1500, Train Loss: 0.0180,       Test Loss: 0.0203, Duration: 0:00:00.027330\n",
      "Epoch 50/1500, Train Loss: 0.0183,       Test Loss: 0.0184, Duration: 0:00:00.027870\n",
      "Epoch 51/1500, Train Loss: 0.0166,       Test Loss: 0.0162, Duration: 0:00:00.026840\n",
      "Epoch 52/1500, Train Loss: 0.0156,       Test Loss: 0.0166, Duration: 0:00:00.027022\n",
      "Epoch 53/1500, Train Loss: 0.0156,       Test Loss: 0.0168, Duration: 0:00:00.026921\n",
      "Epoch 54/1500, Train Loss: 0.0152,       Test Loss: 0.0161, Duration: 0:00:00.026769\n",
      "Epoch 55/1500, Train Loss: 0.0151,       Test Loss: 0.0163, Duration: 0:00:00.026990\n",
      "Epoch 56/1500, Train Loss: 0.0151,       Test Loss: 0.0162, Duration: 0:00:00.027145\n",
      "Epoch 57/1500, Train Loss: 0.0149,       Test Loss: 0.0152, Duration: 0:00:00.027762\n",
      "Epoch 58/1500, Train Loss: 0.0147,       Test Loss: 0.0151, Duration: 0:00:00.027707\n",
      "Epoch 59/1500, Train Loss: 0.0141,       Test Loss: 0.0144, Duration: 0:00:00.026274\n",
      "Epoch 60/1500, Train Loss: 0.0135,       Test Loss: 0.0143, Duration: 0:00:00.026370\n",
      "Epoch 61/1500, Train Loss: 0.0142,       Test Loss: 0.0160, Duration: 0:00:00.026033\n",
      "Epoch 62/1500, Train Loss: 0.0142,       Test Loss: 0.0154, Duration: 0:00:00.025853\n",
      "Epoch 63/1500, Train Loss: 0.0134,       Test Loss: 0.0131, Duration: 0:00:00.026100\n",
      "Epoch 64/1500, Train Loss: 0.0124,       Test Loss: 0.0119, Duration: 0:00:00.025812\n",
      "Epoch 65/1500, Train Loss: 0.0119,       Test Loss: 0.0118, Duration: 0:00:00.027278\n",
      "Epoch 66/1500, Train Loss: 0.0117,       Test Loss: 0.0112, Duration: 0:00:00.026983\n",
      "Epoch 67/1500, Train Loss: 0.0113,       Test Loss: 0.0106, Duration: 0:00:00.026261\n",
      "Epoch 68/1500, Train Loss: 0.0108,       Test Loss: 0.0091, Duration: 0:00:00.025619\n",
      "Epoch 69/1500, Train Loss: 0.0100,       Test Loss: 0.0097, Duration: 0:00:00.025746\n",
      "Epoch 70/1500, Train Loss: 0.0102,       Test Loss: 0.0102, Duration: 0:00:00.025480\n",
      "Epoch 71/1500, Train Loss: 0.0103,       Test Loss: 0.0115, Duration: 0:00:00.025798\n",
      "Epoch 72/1500, Train Loss: 0.0107,       Test Loss: 0.0112, Duration: 0:00:00.025720\n",
      "Epoch 73/1500, Train Loss: 0.0105,       Test Loss: 0.0099, Duration: 0:00:00.026201\n",
      "Epoch 74/1500, Train Loss: 0.0100,       Test Loss: 0.0100, Duration: 0:00:00.026899\n",
      "Epoch 75/1500, Train Loss: 0.0099,       Test Loss: 0.0093, Duration: 0:00:00.025983\n",
      "Epoch 76/1500, Train Loss: 0.0094,       Test Loss: 0.0082, Duration: 0:00:00.025890\n",
      "Epoch 77/1500, Train Loss: 0.0088,       Test Loss: 0.0086, Duration: 0:00:00.026103\n",
      "Epoch 78/1500, Train Loss: 0.0090,       Test Loss: 0.0081, Duration: 0:00:00.025877\n",
      "Epoch 79/1500, Train Loss: 0.0088,       Test Loss: 0.0086, Duration: 0:00:00.025642\n",
      "Epoch 80/1500, Train Loss: 0.0090,       Test Loss: 0.0095, Duration: 0:00:00.025723\n",
      "Epoch 81/1500, Train Loss: 0.0096,       Test Loss: 0.0094, Duration: 0:00:00.026123\n",
      "Epoch 82/1500, Train Loss: 0.0097,       Test Loss: 0.0095, Duration: 0:00:00.026423\n",
      "Epoch 83/1500, Train Loss: 0.0094,       Test Loss: 0.0090, Duration: 0:00:00.026325\n",
      "Epoch 84/1500, Train Loss: 0.0087,       Test Loss: 0.0089, Duration: 0:00:00.026919\n",
      "Epoch 85/1500, Train Loss: 0.0088,       Test Loss: 0.0079, Duration: 0:00:00.026271\n",
      "Epoch 86/1500, Train Loss: 0.0082,       Test Loss: 0.0075, Duration: 0:00:00.025834\n",
      "Epoch 87/1500, Train Loss: 0.0080,       Test Loss: 0.0073, Duration: 0:00:00.025714\n",
      "Epoch 88/1500, Train Loss: 0.0081,       Test Loss: 0.0075, Duration: 0:00:00.025727\n",
      "Epoch 89/1500, Train Loss: 0.0080,       Test Loss: 0.0072, Duration: 0:00:00.026591\n",
      "Epoch 90/1500, Train Loss: 0.0081,       Test Loss: 0.0078, Duration: 0:00:00.026836\n",
      "Epoch 91/1500, Train Loss: 0.0081,       Test Loss: 0.0076, Duration: 0:00:00.026279\n",
      "Epoch 92/1500, Train Loss: 0.0081,       Test Loss: 0.0071, Duration: 0:00:00.026283\n",
      "Epoch 93/1500, Train Loss: 0.0080,       Test Loss: 0.0074, Duration: 0:00:00.026144\n",
      "Epoch 94/1500, Train Loss: 0.0079,       Test Loss: 0.0071, Duration: 0:00:00.025984\n",
      "Epoch 95/1500, Train Loss: 0.0074,       Test Loss: 0.0069, Duration: 0:00:00.026436\n",
      "Epoch 96/1500, Train Loss: 0.0077,       Test Loss: 0.0073, Duration: 0:00:00.025934\n",
      "Epoch 97/1500, Train Loss: 0.0078,       Test Loss: 0.0072, Duration: 0:00:00.026116\n",
      "Epoch 98/1500, Train Loss: 0.0078,       Test Loss: 0.0074, Duration: 0:00:00.026962\n",
      "Epoch 99/1500, Train Loss: 0.0075,       Test Loss: 0.0072, Duration: 0:00:00.026218\n",
      "Epoch 100/1500, Train Loss: 0.0078,       Test Loss: 0.0074, Duration: 0:00:00.026040\n",
      "Epoch 101/1500, Train Loss: 0.0075,       Test Loss: 0.0076, Duration: 0:00:00.026151\n",
      "Epoch 102/1500, Train Loss: 0.0078,       Test Loss: 0.0086, Duration: 0:00:00.025959\n",
      "Epoch 103/1500, Train Loss: 0.0081,       Test Loss: 0.0086, Duration: 0:00:00.026599\n",
      "Epoch 104/1500, Train Loss: 0.0086,       Test Loss: 0.0094, Duration: 0:00:00.025911\n",
      "Epoch 105/1500, Train Loss: 0.0088,       Test Loss: 0.0110, Duration: 0:00:00.026630\n",
      "Epoch 106/1500, Train Loss: 0.0098,       Test Loss: 0.0105, Duration: 0:00:00.026904\n",
      "Epoch 107/1500, Train Loss: 0.0093,       Test Loss: 0.0094, Duration: 0:00:00.025881\n",
      "Epoch 108/1500, Train Loss: 0.0095,       Test Loss: 0.0125, Duration: 0:00:00.025954\n",
      "Epoch 109/1500, Train Loss: 0.0097,       Test Loss: 0.0120, Duration: 0:00:00.026028\n",
      "Epoch 110/1500, Train Loss: 0.0117,       Test Loss: 0.0104, Duration: 0:00:00.025879\n",
      "Epoch 111/1500, Train Loss: 0.0091,       Test Loss: 0.0080, Duration: 0:00:00.025767\n",
      "Epoch 112/1500, Train Loss: 0.0078,       Test Loss: 0.0063, Duration: 0:00:00.025760\n",
      "Epoch 113/1500, Train Loss: 0.0071,       Test Loss: 0.0063, Duration: 0:00:00.026157\n",
      "Epoch 114/1500, Train Loss: 0.0069,       Test Loss: 0.0062, Duration: 0:00:00.026739\n",
      "Epoch 115/1500, Train Loss: 0.0068,       Test Loss: 0.0059, Duration: 0:00:00.026353\n",
      "Epoch 116/1500, Train Loss: 0.0068,       Test Loss: 0.0069, Duration: 0:00:00.026111\n",
      "Epoch 117/1500, Train Loss: 0.0071,       Test Loss: 0.0068, Duration: 0:00:00.025939\n",
      "Epoch 118/1500, Train Loss: 0.0074,       Test Loss: 0.0070, Duration: 0:00:00.025393\n",
      "Epoch 119/1500, Train Loss: 0.0076,       Test Loss: 0.0085, Duration: 0:00:00.025334\n",
      "Epoch 120/1500, Train Loss: 0.0081,       Test Loss: 0.0087, Duration: 0:00:00.025325\n",
      "Epoch 121/1500, Train Loss: 0.0081,       Test Loss: 0.0076, Duration: 0:00:00.025873\n",
      "Epoch 122/1500, Train Loss: 0.0078,       Test Loss: 0.0090, Duration: 0:00:00.026977\n",
      "Epoch 123/1500, Train Loss: 0.0082,       Test Loss: 0.0085, Duration: 0:00:00.025641\n",
      "Epoch 124/1500, Train Loss: 0.0084,       Test Loss: 0.0088, Duration: 0:00:00.025584\n",
      "Epoch 125/1500, Train Loss: 0.0086,       Test Loss: 0.0088, Duration: 0:00:00.025493\n",
      "Epoch 126/1500, Train Loss: 0.0085,       Test Loss: 0.0098, Duration: 0:00:00.025856\n",
      "Epoch 127/1500, Train Loss: 0.0089,       Test Loss: 0.0101, Duration: 0:00:00.025756\n",
      "Epoch 128/1500, Train Loss: 0.0087,       Test Loss: 0.0094, Duration: 0:00:00.025592\n",
      "Epoch 129/1500, Train Loss: 0.0085,       Test Loss: 0.0094, Duration: 0:00:00.025907\n",
      "Epoch 130/1500, Train Loss: 0.0085,       Test Loss: 0.0104, Duration: 0:00:00.026771\n",
      "Epoch 131/1500, Train Loss: 0.0099,       Test Loss: 0.0121, Duration: 0:00:00.026017\n",
      "Epoch 132/1500, Train Loss: 0.0098,       Test Loss: 0.0113, Duration: 0:00:00.025912\n",
      "Epoch 133/1500, Train Loss: 0.0096,       Test Loss: 0.0093, Duration: 0:00:00.026310\n",
      "Epoch 134/1500, Train Loss: 0.0089,       Test Loss: 0.0105, Duration: 0:00:00.025739\n",
      "Epoch 135/1500, Train Loss: 0.0095,       Test Loss: 0.0115, Duration: 0:00:00.025922\n",
      "Epoch 136/1500, Train Loss: 0.0099,       Test Loss: 0.0110, Duration: 0:00:00.025631\n",
      "Epoch 137/1500, Train Loss: 0.0094,       Test Loss: 0.0101, Duration: 0:00:00.026325\n",
      "Epoch 138/1500, Train Loss: 0.0097,       Test Loss: 0.0111, Duration: 0:00:00.026923\n",
      "Epoch 139/1500, Train Loss: 0.0099,       Test Loss: 0.0126, Duration: 0:00:00.026194\n",
      "Epoch 140/1500, Train Loss: 0.0103,       Test Loss: 0.0121, Duration: 0:00:00.025889\n",
      "Epoch 141/1500, Train Loss: 0.0103,       Test Loss: 0.0115, Duration: 0:00:00.026898\n",
      "Epoch 142/1500, Train Loss: 0.0092,       Test Loss: 0.0080, Duration: 0:00:00.025893\n",
      "Epoch 143/1500, Train Loss: 0.0080,       Test Loss: 0.0082, Duration: 0:00:00.025763\n",
      "Epoch 144/1500, Train Loss: 0.0077,       Test Loss: 0.0073, Duration: 0:00:00.025714\n",
      "Epoch 145/1500, Train Loss: 0.0074,       Test Loss: 0.0079, Duration: 0:00:00.026232\n",
      "Epoch 146/1500, Train Loss: 0.0077,       Test Loss: 0.0084, Duration: 0:00:00.026860\n",
      "Epoch 147/1500, Train Loss: 0.0079,       Test Loss: 0.0091, Duration: 0:00:00.026101\n",
      "Epoch 148/1500, Train Loss: 0.0083,       Test Loss: 0.0095, Duration: 0:00:00.025579\n",
      "Epoch 149/1500, Train Loss: 0.0087,       Test Loss: 0.0096, Duration: 0:00:00.025926\n",
      "Epoch 150/1500, Train Loss: 0.0083,       Test Loss: 0.0083, Duration: 0:00:00.025709\n",
      "Epoch 151/1500, Train Loss: 0.0079,       Test Loss: 0.0070, Duration: 0:00:00.025536\n",
      "Epoch 152/1500, Train Loss: 0.0070,       Test Loss: 0.0064, Duration: 0:00:00.025364\n",
      "Epoch 153/1500, Train Loss: 0.0071,       Test Loss: 0.0066, Duration: 0:00:00.026210\n",
      "Epoch 154/1500, Train Loss: 0.0068,       Test Loss: 0.0064, Duration: 0:00:00.026746\n",
      "Epoch 155/1500, Train Loss: 0.0066,       Test Loss: 0.0062, Duration: 0:00:00.026312\n",
      "Epoch 156/1500, Train Loss: 0.0065,       Test Loss: 0.0064, Duration: 0:00:00.026067\n",
      "Epoch 157/1500, Train Loss: 0.0070,       Test Loss: 0.0068, Duration: 0:00:00.025653\n",
      "Epoch 158/1500, Train Loss: 0.0068,       Test Loss: 0.0062, Duration: 0:00:00.025398\n",
      "Epoch 159/1500, Train Loss: 0.0067,       Test Loss: 0.0062, Duration: 0:00:00.025248\n",
      "Epoch 160/1500, Train Loss: 0.0067,       Test Loss: 0.0067, Duration: 0:00:00.025318\n",
      "Epoch 161/1500, Train Loss: 0.0069,       Test Loss: 0.0071, Duration: 0:00:00.026793\n",
      "Epoch 162/1500, Train Loss: 0.0068,       Test Loss: 0.0057, Duration: 0:00:00.027016\n",
      "Epoch 163/1500, Train Loss: 0.0062,       Test Loss: 0.0064, Duration: 0:00:00.026316\n",
      "Epoch 164/1500, Train Loss: 0.0067,       Test Loss: 0.0062, Duration: 0:00:00.025892\n",
      "Epoch 165/1500, Train Loss: 0.0066,       Test Loss: 0.0060, Duration: 0:00:00.025911\n",
      "Epoch 166/1500, Train Loss: 0.0063,       Test Loss: 0.0060, Duration: 0:00:00.025840\n",
      "Epoch 167/1500, Train Loss: 0.0066,       Test Loss: 0.0056, Duration: 0:00:00.025792\n",
      "Epoch 168/1500, Train Loss: 0.0060,       Test Loss: 0.0057, Duration: 0:00:00.025677\n",
      "Epoch 169/1500, Train Loss: 0.0063,       Test Loss: 0.0066, Duration: 0:00:00.025919\n",
      "Epoch 170/1500, Train Loss: 0.0064,       Test Loss: 0.0066, Duration: 0:00:00.026556\n",
      "Epoch 171/1500, Train Loss: 0.0072,       Test Loss: 0.0085, Duration: 0:00:00.025980\n",
      "Epoch 172/1500, Train Loss: 0.0074,       Test Loss: 0.0075, Duration: 0:00:00.026155\n",
      "Epoch 173/1500, Train Loss: 0.0074,       Test Loss: 0.0087, Duration: 0:00:00.025680\n",
      "Epoch 174/1500, Train Loss: 0.0076,       Test Loss: 0.0083, Duration: 0:00:00.025807\n",
      "Epoch 175/1500, Train Loss: 0.0076,       Test Loss: 0.0076, Duration: 0:00:00.025489\n",
      "Epoch 176/1500, Train Loss: 0.0070,       Test Loss: 0.0069, Duration: 0:00:00.025524\n",
      "Epoch 177/1500, Train Loss: 0.0072,       Test Loss: 0.0070, Duration: 0:00:00.025711\n",
      "Epoch 178/1500, Train Loss: 0.0067,       Test Loss: 0.0069, Duration: 0:00:00.027072\n",
      "Epoch 179/1500, Train Loss: 0.0066,       Test Loss: 0.0058, Duration: 0:00:00.026209\n",
      "Epoch 180/1500, Train Loss: 0.0060,       Test Loss: 0.0056, Duration: 0:00:00.026805\n",
      "Epoch 181/1500, Train Loss: 0.0062,       Test Loss: 0.0056, Duration: 0:00:00.025646\n",
      "Epoch 182/1500, Train Loss: 0.0060,       Test Loss: 0.0054, Duration: 0:00:00.026225\n",
      "Epoch 183/1500, Train Loss: 0.0059,       Test Loss: 0.0053, Duration: 0:00:00.025876\n",
      "Epoch 184/1500, Train Loss: 0.0064,       Test Loss: 0.0056, Duration: 0:00:00.025783\n",
      "Epoch 185/1500, Train Loss: 0.0063,       Test Loss: 0.0071, Duration: 0:00:00.026317\n",
      "Epoch 186/1500, Train Loss: 0.0073,       Test Loss: 0.0081, Duration: 0:00:00.027155\n",
      "Epoch 187/1500, Train Loss: 0.0073,       Test Loss: 0.0092, Duration: 0:00:00.026182\n",
      "Epoch 188/1500, Train Loss: 0.0073,       Test Loss: 0.0073, Duration: 0:00:00.026125\n",
      "Epoch 189/1500, Train Loss: 0.0071,       Test Loss: 0.0079, Duration: 0:00:00.025954\n",
      "Epoch 190/1500, Train Loss: 0.0074,       Test Loss: 0.0088, Duration: 0:00:00.025524\n",
      "Epoch 191/1500, Train Loss: 0.0082,       Test Loss: 0.0098, Duration: 0:00:00.025565\n",
      "Epoch 192/1500, Train Loss: 0.0080,       Test Loss: 0.0088, Duration: 0:00:00.025666\n",
      "Epoch 193/1500, Train Loss: 0.0079,       Test Loss: 0.0082, Duration: 0:00:00.026515\n",
      "Epoch 194/1500, Train Loss: 0.0076,       Test Loss: 0.0080, Duration: 0:00:00.026749\n",
      "Epoch 195/1500, Train Loss: 0.0078,       Test Loss: 0.0099, Duration: 0:00:00.026012\n",
      "Epoch 196/1500, Train Loss: 0.0090,       Test Loss: 0.0082, Duration: 0:00:00.025982\n",
      "Epoch 197/1500, Train Loss: 0.0071,       Test Loss: 0.0083, Duration: 0:00:00.025945\n",
      "Epoch 198/1500, Train Loss: 0.0084,       Test Loss: 0.0076, Duration: 0:00:00.025946\n",
      "Epoch 199/1500, Train Loss: 0.0075,       Test Loss: 0.0094, Duration: 0:00:00.026083\n",
      "Epoch 200/1500, Train Loss: 0.0081,       Test Loss: 0.0075, Duration: 0:00:00.025557\n",
      "Epoch 201/1500, Train Loss: 0.0075,       Test Loss: 0.0076, Duration: 0:00:00.026183\n",
      "Epoch 202/1500, Train Loss: 0.0075,       Test Loss: 0.0070, Duration: 0:00:00.026966\n",
      "Epoch 203/1500, Train Loss: 0.0068,       Test Loss: 0.0070, Duration: 0:00:00.026051\n",
      "Epoch 204/1500, Train Loss: 0.0068,       Test Loss: 0.0061, Duration: 0:00:00.026203\n",
      "Epoch 205/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.025986\n",
      "Epoch 206/1500, Train Loss: 0.0062,       Test Loss: 0.0058, Duration: 0:00:00.025781\n",
      "Epoch 207/1500, Train Loss: 0.0061,       Test Loss: 0.0061, Duration: 0:00:00.025582\n",
      "Epoch 208/1500, Train Loss: 0.0062,       Test Loss: 0.0062, Duration: 0:00:00.025322\n",
      "Epoch 209/1500, Train Loss: 0.0066,       Test Loss: 0.0071, Duration: 0:00:00.026402\n",
      "Epoch 210/1500, Train Loss: 0.0067,       Test Loss: 0.0063, Duration: 0:00:00.026590\n",
      "Epoch 211/1500, Train Loss: 0.0065,       Test Loss: 0.0066, Duration: 0:00:00.026177\n",
      "Epoch 212/1500, Train Loss: 0.0061,       Test Loss: 0.0059, Duration: 0:00:00.026027\n",
      "Epoch 213/1500, Train Loss: 0.0060,       Test Loss: 0.0057, Duration: 0:00:00.025857\n",
      "Epoch 214/1500, Train Loss: 0.0060,       Test Loss: 0.0055, Duration: 0:00:00.025572\n",
      "Epoch 215/1500, Train Loss: 0.0061,       Test Loss: 0.0062, Duration: 0:00:00.025708\n",
      "Epoch 216/1500, Train Loss: 0.0067,       Test Loss: 0.0070, Duration: 0:00:00.025673\n",
      "Epoch 217/1500, Train Loss: 0.0070,       Test Loss: 0.0082, Duration: 0:00:00.026248\n",
      "Epoch 218/1500, Train Loss: 0.0072,       Test Loss: 0.0091, Duration: 0:00:00.027373\n",
      "Epoch 219/1500, Train Loss: 0.0082,       Test Loss: 0.0129, Duration: 0:00:00.026349\n",
      "Epoch 220/1500, Train Loss: 0.0105,       Test Loss: 0.0113, Duration: 0:00:00.025948\n",
      "Epoch 221/1500, Train Loss: 0.0092,       Test Loss: 0.0109, Duration: 0:00:00.026196\n",
      "Epoch 222/1500, Train Loss: 0.0087,       Test Loss: 0.0082, Duration: 0:00:00.025866\n",
      "Epoch 223/1500, Train Loss: 0.0075,       Test Loss: 0.0087, Duration: 0:00:00.025704\n",
      "Epoch 224/1500, Train Loss: 0.0080,       Test Loss: 0.0092, Duration: 0:00:00.025631\n",
      "Epoch 225/1500, Train Loss: 0.0082,       Test Loss: 0.0066, Duration: 0:00:00.026122\n",
      "Epoch 226/1500, Train Loss: 0.0069,       Test Loss: 0.0070, Duration: 0:00:00.026595\n",
      "Epoch 227/1500, Train Loss: 0.0074,       Test Loss: 0.0090, Duration: 0:00:00.026049\n",
      "Epoch 228/1500, Train Loss: 0.0076,       Test Loss: 0.0069, Duration: 0:00:00.026068\n",
      "Epoch 229/1500, Train Loss: 0.0066,       Test Loss: 0.0076, Duration: 0:00:00.026227\n",
      "Epoch 230/1500, Train Loss: 0.0067,       Test Loss: 0.0059, Duration: 0:00:00.025831\n",
      "Epoch 231/1500, Train Loss: 0.0062,       Test Loss: 0.0065, Duration: 0:00:00.025668\n",
      "Epoch 232/1500, Train Loss: 0.0062,       Test Loss: 0.0060, Duration: 0:00:00.025524\n",
      "Epoch 233/1500, Train Loss: 0.0060,       Test Loss: 0.0053, Duration: 0:00:00.025953\n",
      "Epoch 234/1500, Train Loss: 0.0055,       Test Loss: 0.0046, Duration: 0:00:00.026653\n",
      "Epoch 235/1500, Train Loss: 0.0055,       Test Loss: 0.0052, Duration: 0:00:00.026374\n",
      "Epoch 236/1500, Train Loss: 0.0053,       Test Loss: 0.0043, Duration: 0:00:00.025972\n",
      "Epoch 237/1500, Train Loss: 0.0050,       Test Loss: 0.0042, Duration: 0:00:00.026918\n",
      "Epoch 238/1500, Train Loss: 0.0050,       Test Loss: 0.0048, Duration: 0:00:00.026190\n",
      "Epoch 239/1500, Train Loss: 0.0053,       Test Loss: 0.0044, Duration: 0:00:00.025869\n",
      "Epoch 240/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.025913\n",
      "Epoch 241/1500, Train Loss: 0.0056,       Test Loss: 0.0049, Duration: 0:00:00.026326\n",
      "Epoch 242/1500, Train Loss: 0.0054,       Test Loss: 0.0054, Duration: 0:00:00.026725\n",
      "Epoch 243/1500, Train Loss: 0.0060,       Test Loss: 0.0057, Duration: 0:00:00.026043\n",
      "Epoch 244/1500, Train Loss: 0.0059,       Test Loss: 0.0051, Duration: 0:00:00.026066\n",
      "Epoch 245/1500, Train Loss: 0.0055,       Test Loss: 0.0053, Duration: 0:00:00.026017\n",
      "Epoch 246/1500, Train Loss: 0.0055,       Test Loss: 0.0044, Duration: 0:00:00.025471\n",
      "Epoch 247/1500, Train Loss: 0.0051,       Test Loss: 0.0042, Duration: 0:00:00.025748\n",
      "Epoch 248/1500, Train Loss: 0.0050,       Test Loss: 0.0040, Duration: 0:00:00.025863\n",
      "Epoch 249/1500, Train Loss: 0.0048,       Test Loss: 0.0043, Duration: 0:00:00.026216\n",
      "Epoch 250/1500, Train Loss: 0.0052,       Test Loss: 0.0049, Duration: 0:00:00.026921\n",
      "Epoch 251/1500, Train Loss: 0.0055,       Test Loss: 0.0048, Duration: 0:00:00.026466\n",
      "Epoch 252/1500, Train Loss: 0.0053,       Test Loss: 0.0050, Duration: 0:00:00.026083\n",
      "Epoch 253/1500, Train Loss: 0.0054,       Test Loss: 0.0059, Duration: 0:00:00.026426\n",
      "Epoch 254/1500, Train Loss: 0.0059,       Test Loss: 0.0054, Duration: 0:00:00.025768\n",
      "Epoch 255/1500, Train Loss: 0.0059,       Test Loss: 0.0059, Duration: 0:00:00.025720\n",
      "Epoch 256/1500, Train Loss: 0.0066,       Test Loss: 0.0074, Duration: 0:00:00.026434\n",
      "Epoch 257/1500, Train Loss: 0.0071,       Test Loss: 0.0093, Duration: 0:00:00.027895\n",
      "Epoch 258/1500, Train Loss: 0.0084,       Test Loss: 0.0101, Duration: 0:00:00.027723\n",
      "Epoch 259/1500, Train Loss: 0.0089,       Test Loss: 0.0130, Duration: 0:00:00.027187\n",
      "Epoch 260/1500, Train Loss: 0.0100,       Test Loss: 0.0119, Duration: 0:00:00.027124\n",
      "Epoch 261/1500, Train Loss: 0.0095,       Test Loss: 0.0098, Duration: 0:00:00.026439\n",
      "Epoch 262/1500, Train Loss: 0.0087,       Test Loss: 0.0088, Duration: 0:00:00.027028\n",
      "Epoch 263/1500, Train Loss: 0.0077,       Test Loss: 0.0060, Duration: 0:00:00.026745\n",
      "Epoch 264/1500, Train Loss: 0.0062,       Test Loss: 0.0052, Duration: 0:00:00.026785\n",
      "Epoch 265/1500, Train Loss: 0.0058,       Test Loss: 0.0054, Duration: 0:00:00.027371\n",
      "Epoch 266/1500, Train Loss: 0.0056,       Test Loss: 0.0049, Duration: 0:00:00.027597\n",
      "Epoch 267/1500, Train Loss: 0.0055,       Test Loss: 0.0051, Duration: 0:00:00.027001\n",
      "Epoch 268/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026643\n",
      "Epoch 269/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026594\n",
      "Epoch 270/1500, Train Loss: 0.0056,       Test Loss: 0.0063, Duration: 0:00:00.026787\n",
      "Epoch 271/1500, Train Loss: 0.0061,       Test Loss: 0.0066, Duration: 0:00:00.026674\n",
      "Epoch 272/1500, Train Loss: 0.0072,       Test Loss: 0.0083, Duration: 0:00:00.026487\n",
      "Epoch 273/1500, Train Loss: 0.0077,       Test Loss: 0.0092, Duration: 0:00:00.027499\n",
      "Epoch 274/1500, Train Loss: 0.0083,       Test Loss: 0.0105, Duration: 0:00:00.027360\n",
      "Epoch 275/1500, Train Loss: 0.0089,       Test Loss: 0.0112, Duration: 0:00:00.027575\n",
      "Epoch 276/1500, Train Loss: 0.0090,       Test Loss: 0.0113, Duration: 0:00:00.026673\n",
      "Epoch 277/1500, Train Loss: 0.0096,       Test Loss: 0.0139, Duration: 0:00:00.026280\n",
      "Epoch 278/1500, Train Loss: 0.0101,       Test Loss: 0.0092, Duration: 0:00:00.026028\n",
      "Epoch 279/1500, Train Loss: 0.0077,       Test Loss: 0.0091, Duration: 0:00:00.026246\n",
      "Epoch 280/1500, Train Loss: 0.0085,       Test Loss: 0.0122, Duration: 0:00:00.025735\n",
      "Epoch 281/1500, Train Loss: 0.0089,       Test Loss: 0.0102, Duration: 0:00:00.026561\n",
      "Epoch 282/1500, Train Loss: 0.0085,       Test Loss: 0.0080, Duration: 0:00:00.027482\n",
      "Epoch 283/1500, Train Loss: 0.0077,       Test Loss: 0.0076, Duration: 0:00:00.026966\n",
      "Epoch 284/1500, Train Loss: 0.0066,       Test Loss: 0.0071, Duration: 0:00:00.026694\n",
      "Epoch 285/1500, Train Loss: 0.0070,       Test Loss: 0.0075, Duration: 0:00:00.026933\n",
      "Epoch 286/1500, Train Loss: 0.0067,       Test Loss: 0.0068, Duration: 0:00:00.027138\n",
      "Epoch 287/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.026727\n",
      "Epoch 288/1500, Train Loss: 0.0064,       Test Loss: 0.0067, Duration: 0:00:00.026668\n",
      "Epoch 289/1500, Train Loss: 0.0064,       Test Loss: 0.0060, Duration: 0:00:00.027236\n",
      "Epoch 290/1500, Train Loss: 0.0060,       Test Loss: 0.0058, Duration: 0:00:00.027536\n",
      "Epoch 291/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.026799\n",
      "Epoch 292/1500, Train Loss: 0.0060,       Test Loss: 0.0069, Duration: 0:00:00.026845\n",
      "Epoch 293/1500, Train Loss: 0.0064,       Test Loss: 0.0060, Duration: 0:00:00.026890\n",
      "Epoch 294/1500, Train Loss: 0.0062,       Test Loss: 0.0076, Duration: 0:00:00.026842\n",
      "Epoch 295/1500, Train Loss: 0.0064,       Test Loss: 0.0063, Duration: 0:00:00.025915\n",
      "Epoch 296/1500, Train Loss: 0.0063,       Test Loss: 0.0067, Duration: 0:00:00.025631\n",
      "Epoch 297/1500, Train Loss: 0.0063,       Test Loss: 0.0058, Duration: 0:00:00.026241\n",
      "Epoch 298/1500, Train Loss: 0.0059,       Test Loss: 0.0050, Duration: 0:00:00.026881\n",
      "Epoch 299/1500, Train Loss: 0.0061,       Test Loss: 0.0065, Duration: 0:00:00.026170\n",
      "Epoch 300/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.025911\n",
      "Epoch 301/1500, Train Loss: 0.0068,       Test Loss: 0.0084, Duration: 0:00:00.026129\n",
      "Epoch 302/1500, Train Loss: 0.0074,       Test Loss: 0.0080, Duration: 0:00:00.025583\n",
      "Epoch 303/1500, Train Loss: 0.0065,       Test Loss: 0.0064, Duration: 0:00:00.026354\n",
      "Epoch 304/1500, Train Loss: 0.0064,       Test Loss: 0.0070, Duration: 0:00:00.025874\n",
      "Epoch 305/1500, Train Loss: 0.0069,       Test Loss: 0.0078, Duration: 0:00:00.026738\n",
      "Epoch 306/1500, Train Loss: 0.0072,       Test Loss: 0.0077, Duration: 0:00:00.028060\n",
      "Epoch 307/1500, Train Loss: 0.0065,       Test Loss: 0.0055, Duration: 0:00:00.027080\n",
      "Epoch 308/1500, Train Loss: 0.0059,       Test Loss: 0.0061, Duration: 0:00:00.026898\n",
      "Epoch 309/1500, Train Loss: 0.0058,       Test Loss: 0.0054, Duration: 0:00:00.026854\n",
      "Epoch 310/1500, Train Loss: 0.0057,       Test Loss: 0.0063, Duration: 0:00:00.026995\n",
      "Epoch 311/1500, Train Loss: 0.0064,       Test Loss: 0.0077, Duration: 0:00:00.026759\n",
      "Epoch 312/1500, Train Loss: 0.0070,       Test Loss: 0.0079, Duration: 0:00:00.026786\n",
      "Epoch 313/1500, Train Loss: 0.0075,       Test Loss: 0.0089, Duration: 0:00:00.027930\n",
      "Epoch 314/1500, Train Loss: 0.0081,       Test Loss: 0.0103, Duration: 0:00:00.027934\n",
      "Epoch 315/1500, Train Loss: 0.0086,       Test Loss: 0.0106, Duration: 0:00:00.027223\n",
      "Epoch 316/1500, Train Loss: 0.0087,       Test Loss: 0.0094, Duration: 0:00:00.027013\n",
      "Epoch 317/1500, Train Loss: 0.0082,       Test Loss: 0.0086, Duration: 0:00:00.030304\n",
      "Epoch 318/1500, Train Loss: 0.0077,       Test Loss: 0.0091, Duration: 0:00:00.032516\n",
      "Epoch 319/1500, Train Loss: 0.0072,       Test Loss: 0.0096, Duration: 0:00:00.031140\n",
      "Epoch 320/1500, Train Loss: 0.0078,       Test Loss: 0.0082, Duration: 0:00:00.030612\n",
      "Epoch 321/1500, Train Loss: 0.0075,       Test Loss: 0.0087, Duration: 0:00:00.028496\n",
      "Epoch 322/1500, Train Loss: 0.0075,       Test Loss: 0.0070, Duration: 0:00:00.026986\n",
      "Epoch 323/1500, Train Loss: 0.0069,       Test Loss: 0.0071, Duration: 0:00:00.026408\n",
      "Epoch 324/1500, Train Loss: 0.0064,       Test Loss: 0.0060, Duration: 0:00:00.027456\n",
      "Epoch 325/1500, Train Loss: 0.0065,       Test Loss: 0.0066, Duration: 0:00:00.026987\n",
      "Epoch 326/1500, Train Loss: 0.0065,       Test Loss: 0.0068, Duration: 0:00:00.027443\n",
      "Epoch 327/1500, Train Loss: 0.0070,       Test Loss: 0.0071, Duration: 0:00:00.026902\n",
      "Epoch 328/1500, Train Loss: 0.0068,       Test Loss: 0.0077, Duration: 0:00:00.027391\n",
      "Epoch 329/1500, Train Loss: 0.0073,       Test Loss: 0.0082, Duration: 0:00:00.028158\n",
      "Epoch 330/1500, Train Loss: 0.0084,       Test Loss: 0.0120, Duration: 0:00:00.028008\n",
      "Epoch 331/1500, Train Loss: 0.0093,       Test Loss: 0.0100, Duration: 0:00:00.026583\n",
      "Epoch 332/1500, Train Loss: 0.0083,       Test Loss: 0.0069, Duration: 0:00:00.027533\n",
      "Epoch 333/1500, Train Loss: 0.0071,       Test Loss: 0.0087, Duration: 0:00:00.026673\n",
      "Epoch 334/1500, Train Loss: 0.0080,       Test Loss: 0.0095, Duration: 0:00:00.027182\n",
      "Epoch 335/1500, Train Loss: 0.0089,       Test Loss: 0.0089, Duration: 0:00:00.026394\n",
      "Epoch 336/1500, Train Loss: 0.0092,       Test Loss: 0.0115, Duration: 0:00:00.027358\n",
      "Epoch 337/1500, Train Loss: 0.0092,       Test Loss: 0.0087, Duration: 0:00:00.028281\n",
      "Epoch 338/1500, Train Loss: 0.0074,       Test Loss: 0.0063, Duration: 0:00:00.026757\n",
      "Epoch 339/1500, Train Loss: 0.0065,       Test Loss: 0.0062, Duration: 0:00:00.026838\n",
      "Epoch 340/1500, Train Loss: 0.0066,       Test Loss: 0.0075, Duration: 0:00:00.026415\n",
      "Epoch 341/1500, Train Loss: 0.0071,       Test Loss: 0.0072, Duration: 0:00:00.026694\n",
      "Epoch 342/1500, Train Loss: 0.0066,       Test Loss: 0.0071, Duration: 0:00:00.027206\n",
      "Epoch 343/1500, Train Loss: 0.0074,       Test Loss: 0.0085, Duration: 0:00:00.026454\n",
      "Epoch 344/1500, Train Loss: 0.0076,       Test Loss: 0.0071, Duration: 0:00:00.027633\n",
      "Epoch 345/1500, Train Loss: 0.0068,       Test Loss: 0.0068, Duration: 0:00:00.028013\n",
      "Epoch 346/1500, Train Loss: 0.0072,       Test Loss: 0.0091, Duration: 0:00:00.027135\n",
      "Epoch 347/1500, Train Loss: 0.0079,       Test Loss: 0.0072, Duration: 0:00:00.027040\n",
      "Epoch 348/1500, Train Loss: 0.0066,       Test Loss: 0.0062, Duration: 0:00:00.027012\n",
      "Epoch 349/1500, Train Loss: 0.0061,       Test Loss: 0.0058, Duration: 0:00:00.027425\n",
      "Epoch 350/1500, Train Loss: 0.0062,       Test Loss: 0.0061, Duration: 0:00:00.027442\n",
      "Epoch 351/1500, Train Loss: 0.0059,       Test Loss: 0.0051, Duration: 0:00:00.026932\n",
      "Epoch 352/1500, Train Loss: 0.0054,       Test Loss: 0.0049, Duration: 0:00:00.027179\n",
      "Epoch 353/1500, Train Loss: 0.0054,       Test Loss: 0.0047, Duration: 0:00:00.027642\n",
      "Epoch 354/1500, Train Loss: 0.0052,       Test Loss: 0.0043, Duration: 0:00:00.026260\n",
      "Epoch 355/1500, Train Loss: 0.0052,       Test Loss: 0.0045, Duration: 0:00:00.027149\n",
      "Epoch 356/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.026338\n",
      "Epoch 357/1500, Train Loss: 0.0057,       Test Loss: 0.0055, Duration: 0:00:00.026021\n",
      "Epoch 358/1500, Train Loss: 0.0056,       Test Loss: 0.0046, Duration: 0:00:00.026034\n",
      "Epoch 359/1500, Train Loss: 0.0053,       Test Loss: 0.0046, Duration: 0:00:00.026211\n",
      "Epoch 360/1500, Train Loss: 0.0053,       Test Loss: 0.0048, Duration: 0:00:00.026727\n",
      "Epoch 361/1500, Train Loss: 0.0057,       Test Loss: 0.0044, Duration: 0:00:00.027098\n",
      "Epoch 362/1500, Train Loss: 0.0053,       Test Loss: 0.0042, Duration: 0:00:00.025956\n",
      "Epoch 363/1500, Train Loss: 0.0049,       Test Loss: 0.0044, Duration: 0:00:00.026318\n",
      "Epoch 364/1500, Train Loss: 0.0053,       Test Loss: 0.0041, Duration: 0:00:00.026213\n",
      "Epoch 365/1500, Train Loss: 0.0047,       Test Loss: 0.0042, Duration: 0:00:00.026160\n",
      "Epoch 366/1500, Train Loss: 0.0049,       Test Loss: 0.0044, Duration: 0:00:00.025636\n",
      "Epoch 367/1500, Train Loss: 0.0049,       Test Loss: 0.0043, Duration: 0:00:00.026897\n",
      "Epoch 368/1500, Train Loss: 0.0050,       Test Loss: 0.0045, Duration: 0:00:00.026598\n",
      "Epoch 369/1500, Train Loss: 0.0048,       Test Loss: 0.0043, Duration: 0:00:00.027040\n",
      "Epoch 370/1500, Train Loss: 0.0049,       Test Loss: 0.0044, Duration: 0:00:00.026102\n",
      "Epoch 371/1500, Train Loss: 0.0053,       Test Loss: 0.0062, Duration: 0:00:00.026398\n",
      "Epoch 372/1500, Train Loss: 0.0060,       Test Loss: 0.0068, Duration: 0:00:00.026240\n",
      "Epoch 373/1500, Train Loss: 0.0066,       Test Loss: 0.0060, Duration: 0:00:00.025891\n",
      "Epoch 374/1500, Train Loss: 0.0061,       Test Loss: 0.0069, Duration: 0:00:00.025971\n",
      "Epoch 375/1500, Train Loss: 0.0072,       Test Loss: 0.0075, Duration: 0:00:00.026046\n",
      "Epoch 376/1500, Train Loss: 0.0066,       Test Loss: 0.0079, Duration: 0:00:00.026882\n",
      "Epoch 377/1500, Train Loss: 0.0069,       Test Loss: 0.0062, Duration: 0:00:00.027342\n",
      "Epoch 378/1500, Train Loss: 0.0064,       Test Loss: 0.0065, Duration: 0:00:00.026188\n",
      "Epoch 379/1500, Train Loss: 0.0063,       Test Loss: 0.0065, Duration: 0:00:00.025882\n",
      "Epoch 380/1500, Train Loss: 0.0061,       Test Loss: 0.0055, Duration: 0:00:00.026047\n",
      "Epoch 381/1500, Train Loss: 0.0059,       Test Loss: 0.0073, Duration: 0:00:00.026303\n",
      "Epoch 382/1500, Train Loss: 0.0066,       Test Loss: 0.0075, Duration: 0:00:00.026340\n",
      "Epoch 383/1500, Train Loss: 0.0071,       Test Loss: 0.0064, Duration: 0:00:00.026077\n",
      "Epoch 384/1500, Train Loss: 0.0060,       Test Loss: 0.0056, Duration: 0:00:00.026980\n",
      "Epoch 385/1500, Train Loss: 0.0058,       Test Loss: 0.0052, Duration: 0:00:00.027410\n",
      "Epoch 386/1500, Train Loss: 0.0058,       Test Loss: 0.0066, Duration: 0:00:00.027344\n",
      "Epoch 387/1500, Train Loss: 0.0059,       Test Loss: 0.0053, Duration: 0:00:00.026507\n",
      "Epoch 388/1500, Train Loss: 0.0055,       Test Loss: 0.0053, Duration: 0:00:00.026192\n",
      "Epoch 389/1500, Train Loss: 0.0054,       Test Loss: 0.0045, Duration: 0:00:00.026376\n",
      "Epoch 390/1500, Train Loss: 0.0049,       Test Loss: 0.0044, Duration: 0:00:00.026382\n",
      "Epoch 391/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.026124\n",
      "Epoch 392/1500, Train Loss: 0.0051,       Test Loss: 0.0045, Duration: 0:00:00.026740\n",
      "Epoch 393/1500, Train Loss: 0.0049,       Test Loss: 0.0043, Duration: 0:00:00.027461\n",
      "Epoch 394/1500, Train Loss: 0.0049,       Test Loss: 0.0046, Duration: 0:00:00.026179\n",
      "Epoch 395/1500, Train Loss: 0.0049,       Test Loss: 0.0043, Duration: 0:00:00.026411\n",
      "Epoch 396/1500, Train Loss: 0.0051,       Test Loss: 0.0046, Duration: 0:00:00.025845\n",
      "Epoch 397/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.026009\n",
      "Epoch 398/1500, Train Loss: 0.0049,       Test Loss: 0.0053, Duration: 0:00:00.025579\n",
      "Epoch 399/1500, Train Loss: 0.0054,       Test Loss: 0.0050, Duration: 0:00:00.026005\n",
      "Epoch 400/1500, Train Loss: 0.0062,       Test Loss: 0.0062, Duration: 0:00:00.026458\n",
      "Epoch 401/1500, Train Loss: 0.0055,       Test Loss: 0.0054, Duration: 0:00:00.027354\n",
      "Epoch 402/1500, Train Loss: 0.0058,       Test Loss: 0.0073, Duration: 0:00:00.026111\n",
      "Epoch 403/1500, Train Loss: 0.0074,       Test Loss: 0.0092, Duration: 0:00:00.026132\n",
      "Epoch 404/1500, Train Loss: 0.0090,       Test Loss: 0.0159, Duration: 0:00:00.025686\n",
      "Epoch 405/1500, Train Loss: 0.0131,       Test Loss: 0.0184, Duration: 0:00:00.026480\n",
      "Epoch 406/1500, Train Loss: 0.0142,       Test Loss: 0.0171, Duration: 0:00:00.025778\n",
      "Epoch 407/1500, Train Loss: 0.0142,       Test Loss: 0.0123, Duration: 0:00:00.025710\n",
      "Epoch 408/1500, Train Loss: 0.0094,       Test Loss: 0.0110, Duration: 0:00:00.026423\n",
      "Epoch 409/1500, Train Loss: 0.0091,       Test Loss: 0.0099, Duration: 0:00:00.027647\n",
      "Epoch 410/1500, Train Loss: 0.0079,       Test Loss: 0.0079, Duration: 0:00:00.026483\n",
      "Epoch 411/1500, Train Loss: 0.0072,       Test Loss: 0.0085, Duration: 0:00:00.025852\n",
      "Epoch 412/1500, Train Loss: 0.0077,       Test Loss: 0.0084, Duration: 0:00:00.025954\n",
      "Epoch 413/1500, Train Loss: 0.0081,       Test Loss: 0.0058, Duration: 0:00:00.026010\n",
      "Epoch 414/1500, Train Loss: 0.0062,       Test Loss: 0.0056, Duration: 0:00:00.026214\n",
      "Epoch 415/1500, Train Loss: 0.0057,       Test Loss: 0.0050, Duration: 0:00:00.025997\n",
      "Epoch 416/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.026904\n",
      "Epoch 417/1500, Train Loss: 0.0057,       Test Loss: 0.0052, Duration: 0:00:00.026603\n",
      "Epoch 418/1500, Train Loss: 0.0055,       Test Loss: 0.0052, Duration: 0:00:00.026377\n",
      "Epoch 419/1500, Train Loss: 0.0055,       Test Loss: 0.0054, Duration: 0:00:00.026175\n",
      "Epoch 420/1500, Train Loss: 0.0058,       Test Loss: 0.0055, Duration: 0:00:00.026237\n",
      "Epoch 421/1500, Train Loss: 0.0061,       Test Loss: 0.0077, Duration: 0:00:00.025868\n",
      "Epoch 422/1500, Train Loss: 0.0072,       Test Loss: 0.0073, Duration: 0:00:00.026148\n",
      "Epoch 423/1500, Train Loss: 0.0070,       Test Loss: 0.0069, Duration: 0:00:00.025774\n",
      "Epoch 424/1500, Train Loss: 0.0062,       Test Loss: 0.0065, Duration: 0:00:00.027343\n",
      "Epoch 425/1500, Train Loss: 0.0070,       Test Loss: 0.0079, Duration: 0:00:00.027479\n",
      "Epoch 426/1500, Train Loss: 0.0068,       Test Loss: 0.0065, Duration: 0:00:00.025883\n",
      "Epoch 427/1500, Train Loss: 0.0062,       Test Loss: 0.0064, Duration: 0:00:00.025787\n",
      "Epoch 428/1500, Train Loss: 0.0067,       Test Loss: 0.0053, Duration: 0:00:00.025689\n",
      "Epoch 429/1500, Train Loss: 0.0058,       Test Loss: 0.0061, Duration: 0:00:00.025729\n",
      "Epoch 430/1500, Train Loss: 0.0057,       Test Loss: 0.0051, Duration: 0:00:00.025690\n",
      "Epoch 431/1500, Train Loss: 0.0057,       Test Loss: 0.0052, Duration: 0:00:00.025951\n",
      "Epoch 432/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.026824\n",
      "Epoch 433/1500, Train Loss: 0.0055,       Test Loss: 0.0054, Duration: 0:00:00.027133\n",
      "Epoch 434/1500, Train Loss: 0.0058,       Test Loss: 0.0059, Duration: 0:00:00.026109\n",
      "Epoch 435/1500, Train Loss: 0.0059,       Test Loss: 0.0063, Duration: 0:00:00.026193\n",
      "Epoch 436/1500, Train Loss: 0.0061,       Test Loss: 0.0064, Duration: 0:00:00.025552\n",
      "Epoch 437/1500, Train Loss: 0.0062,       Test Loss: 0.0064, Duration: 0:00:00.026003\n",
      "Epoch 438/1500, Train Loss: 0.0066,       Test Loss: 0.0067, Duration: 0:00:00.026186\n",
      "Epoch 439/1500, Train Loss: 0.0064,       Test Loss: 0.0069, Duration: 0:00:00.026266\n",
      "Epoch 440/1500, Train Loss: 0.0065,       Test Loss: 0.0071, Duration: 0:00:00.026437\n",
      "Epoch 441/1500, Train Loss: 0.0072,       Test Loss: 0.0067, Duration: 0:00:00.027297\n",
      "Epoch 442/1500, Train Loss: 0.0061,       Test Loss: 0.0073, Duration: 0:00:00.026072\n",
      "Epoch 443/1500, Train Loss: 0.0068,       Test Loss: 0.0084, Duration: 0:00:00.026778\n",
      "Epoch 444/1500, Train Loss: 0.0070,       Test Loss: 0.0073, Duration: 0:00:00.026139\n",
      "Epoch 445/1500, Train Loss: 0.0062,       Test Loss: 0.0061, Duration: 0:00:00.025904\n",
      "Epoch 446/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.025849\n",
      "Epoch 447/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.025850\n",
      "Epoch 448/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.026585\n",
      "Epoch 449/1500, Train Loss: 0.0071,       Test Loss: 0.0087, Duration: 0:00:00.027272\n",
      "Epoch 450/1500, Train Loss: 0.0081,       Test Loss: 0.0094, Duration: 0:00:00.026727\n",
      "Epoch 451/1500, Train Loss: 0.0084,       Test Loss: 0.0070, Duration: 0:00:00.025734\n",
      "Epoch 452/1500, Train Loss: 0.0066,       Test Loss: 0.0058, Duration: 0:00:00.025979\n",
      "Epoch 453/1500, Train Loss: 0.0057,       Test Loss: 0.0053, Duration: 0:00:00.026141\n",
      "Epoch 454/1500, Train Loss: 0.0057,       Test Loss: 0.0051, Duration: 0:00:00.026170\n",
      "Epoch 455/1500, Train Loss: 0.0053,       Test Loss: 0.0056, Duration: 0:00:00.026039\n",
      "Epoch 456/1500, Train Loss: 0.0056,       Test Loss: 0.0046, Duration: 0:00:00.026735\n",
      "Epoch 457/1500, Train Loss: 0.0051,       Test Loss: 0.0052, Duration: 0:00:00.027239\n",
      "Epoch 458/1500, Train Loss: 0.0055,       Test Loss: 0.0053, Duration: 0:00:00.026543\n",
      "Epoch 459/1500, Train Loss: 0.0053,       Test Loss: 0.0056, Duration: 0:00:00.025960\n",
      "Epoch 460/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.026199\n",
      "Epoch 461/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.025608\n",
      "Epoch 462/1500, Train Loss: 0.0059,       Test Loss: 0.0071, Duration: 0:00:00.027349\n",
      "Epoch 463/1500, Train Loss: 0.0065,       Test Loss: 0.0059, Duration: 0:00:00.026385\n",
      "Epoch 464/1500, Train Loss: 0.0059,       Test Loss: 0.0053, Duration: 0:00:00.026673\n",
      "Epoch 465/1500, Train Loss: 0.0055,       Test Loss: 0.0056, Duration: 0:00:00.027489\n",
      "Epoch 466/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.026256\n",
      "Epoch 467/1500, Train Loss: 0.0061,       Test Loss: 0.0065, Duration: 0:00:00.026143\n",
      "Epoch 468/1500, Train Loss: 0.0061,       Test Loss: 0.0060, Duration: 0:00:00.025795\n",
      "Epoch 469/1500, Train Loss: 0.0055,       Test Loss: 0.0063, Duration: 0:00:00.025781\n",
      "Epoch 470/1500, Train Loss: 0.0060,       Test Loss: 0.0062, Duration: 0:00:00.025577\n",
      "Epoch 471/1500, Train Loss: 0.0064,       Test Loss: 0.0070, Duration: 0:00:00.025804\n",
      "Epoch 472/1500, Train Loss: 0.0068,       Test Loss: 0.0074, Duration: 0:00:00.026711\n",
      "Epoch 473/1500, Train Loss: 0.0068,       Test Loss: 0.0088, Duration: 0:00:00.027008\n",
      "Epoch 474/1500, Train Loss: 0.0067,       Test Loss: 0.0060, Duration: 0:00:00.025974\n",
      "Epoch 475/1500, Train Loss: 0.0059,       Test Loss: 0.0059, Duration: 0:00:00.026522\n",
      "Epoch 476/1500, Train Loss: 0.0057,       Test Loss: 0.0070, Duration: 0:00:00.026232\n",
      "Epoch 477/1500, Train Loss: 0.0067,       Test Loss: 0.0090, Duration: 0:00:00.026180\n",
      "Epoch 478/1500, Train Loss: 0.0073,       Test Loss: 0.0085, Duration: 0:00:00.025576\n",
      "Epoch 479/1500, Train Loss: 0.0075,       Test Loss: 0.0063, Duration: 0:00:00.026392\n",
      "Epoch 480/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.027007\n",
      "Epoch 481/1500, Train Loss: 0.0057,       Test Loss: 0.0050, Duration: 0:00:00.027663\n",
      "Epoch 482/1500, Train Loss: 0.0054,       Test Loss: 0.0055, Duration: 0:00:00.026589\n",
      "Epoch 483/1500, Train Loss: 0.0055,       Test Loss: 0.0049, Duration: 0:00:00.026249\n",
      "Epoch 484/1500, Train Loss: 0.0050,       Test Loss: 0.0042, Duration: 0:00:00.026255\n",
      "Epoch 485/1500, Train Loss: 0.0048,       Test Loss: 0.0041, Duration: 0:00:00.026073\n",
      "Epoch 486/1500, Train Loss: 0.0048,       Test Loss: 0.0051, Duration: 0:00:00.026065\n",
      "Epoch 487/1500, Train Loss: 0.0057,       Test Loss: 0.0056, Duration: 0:00:00.026007\n",
      "Epoch 488/1500, Train Loss: 0.0055,       Test Loss: 0.0047, Duration: 0:00:00.026513\n",
      "Epoch 489/1500, Train Loss: 0.0056,       Test Loss: 0.0053, Duration: 0:00:00.027230\n",
      "Epoch 490/1500, Train Loss: 0.0052,       Test Loss: 0.0046, Duration: 0:00:00.026478\n",
      "Epoch 491/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.025988\n",
      "Epoch 492/1500, Train Loss: 0.0056,       Test Loss: 0.0067, Duration: 0:00:00.025853\n",
      "Epoch 493/1500, Train Loss: 0.0062,       Test Loss: 0.0060, Duration: 0:00:00.025530\n",
      "Epoch 494/1500, Train Loss: 0.0058,       Test Loss: 0.0061, Duration: 0:00:00.026428\n",
      "Epoch 495/1500, Train Loss: 0.0057,       Test Loss: 0.0054, Duration: 0:00:00.025968\n",
      "Epoch 496/1500, Train Loss: 0.0055,       Test Loss: 0.0058, Duration: 0:00:00.026691\n",
      "Epoch 497/1500, Train Loss: 0.0057,       Test Loss: 0.0052, Duration: 0:00:00.026792\n",
      "Epoch 498/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.026251\n",
      "Epoch 499/1500, Train Loss: 0.0065,       Test Loss: 0.0071, Duration: 0:00:00.026055\n",
      "Epoch 500/1500, Train Loss: 0.0069,       Test Loss: 0.0079, Duration: 0:00:00.026442\n",
      "Epoch 501/1500, Train Loss: 0.0077,       Test Loss: 0.0082, Duration: 0:00:00.026345\n",
      "Epoch 502/1500, Train Loss: 0.0079,       Test Loss: 0.0112, Duration: 0:00:00.026033\n",
      "Epoch 503/1500, Train Loss: 0.0092,       Test Loss: 0.0121, Duration: 0:00:00.026054\n",
      "Epoch 504/1500, Train Loss: 0.0095,       Test Loss: 0.0068, Duration: 0:00:00.026357\n",
      "Epoch 505/1500, Train Loss: 0.0061,       Test Loss: 0.0060, Duration: 0:00:00.027337\n",
      "Epoch 506/1500, Train Loss: 0.0064,       Test Loss: 0.0063, Duration: 0:00:00.025747\n",
      "Epoch 507/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.025762\n",
      "Epoch 508/1500, Train Loss: 0.0061,       Test Loss: 0.0051, Duration: 0:00:00.025527\n",
      "Epoch 509/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.026173\n",
      "Epoch 510/1500, Train Loss: 0.0053,       Test Loss: 0.0049, Duration: 0:00:00.025968\n",
      "Epoch 511/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.026401\n",
      "Epoch 512/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.026540\n",
      "Epoch 513/1500, Train Loss: 0.0055,       Test Loss: 0.0049, Duration: 0:00:00.027461\n",
      "Epoch 514/1500, Train Loss: 0.0062,       Test Loss: 0.0072, Duration: 0:00:00.026368\n",
      "Epoch 515/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.026275\n",
      "Epoch 516/1500, Train Loss: 0.0064,       Test Loss: 0.0084, Duration: 0:00:00.025805\n",
      "Epoch 517/1500, Train Loss: 0.0068,       Test Loss: 0.0094, Duration: 0:00:00.026104\n",
      "Epoch 518/1500, Train Loss: 0.0084,       Test Loss: 0.0117, Duration: 0:00:00.025885\n",
      "Epoch 519/1500, Train Loss: 0.0080,       Test Loss: 0.0100, Duration: 0:00:00.026367\n",
      "Epoch 520/1500, Train Loss: 0.0092,       Test Loss: 0.0123, Duration: 0:00:00.027244\n",
      "Epoch 521/1500, Train Loss: 0.0093,       Test Loss: 0.0094, Duration: 0:00:00.027259\n",
      "Epoch 522/1500, Train Loss: 0.0084,       Test Loss: 0.0091, Duration: 0:00:00.026386\n",
      "Epoch 523/1500, Train Loss: 0.0075,       Test Loss: 0.0081, Duration: 0:00:00.026152\n",
      "Epoch 524/1500, Train Loss: 0.0068,       Test Loss: 0.0059, Duration: 0:00:00.026245\n",
      "Epoch 525/1500, Train Loss: 0.0060,       Test Loss: 0.0064, Duration: 0:00:00.025982\n",
      "Epoch 526/1500, Train Loss: 0.0064,       Test Loss: 0.0088, Duration: 0:00:00.026093\n",
      "Epoch 527/1500, Train Loss: 0.0088,       Test Loss: 0.0097, Duration: 0:00:00.025870\n",
      "Epoch 528/1500, Train Loss: 0.0088,       Test Loss: 0.0098, Duration: 0:00:00.026952\n",
      "Epoch 529/1500, Train Loss: 0.0081,       Test Loss: 0.0100, Duration: 0:00:00.026958\n",
      "Epoch 530/1500, Train Loss: 0.0084,       Test Loss: 0.0121, Duration: 0:00:00.026638\n",
      "Epoch 531/1500, Train Loss: 0.0084,       Test Loss: 0.0103, Duration: 0:00:00.026157\n",
      "Epoch 532/1500, Train Loss: 0.0080,       Test Loss: 0.0084, Duration: 0:00:00.026276\n",
      "Epoch 533/1500, Train Loss: 0.0077,       Test Loss: 0.0100, Duration: 0:00:00.026043\n",
      "Epoch 534/1500, Train Loss: 0.0076,       Test Loss: 0.0073, Duration: 0:00:00.026065\n",
      "Epoch 535/1500, Train Loss: 0.0068,       Test Loss: 0.0074, Duration: 0:00:00.025907\n",
      "Epoch 536/1500, Train Loss: 0.0065,       Test Loss: 0.0071, Duration: 0:00:00.026784\n",
      "Epoch 537/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.027308\n",
      "Epoch 538/1500, Train Loss: 0.0061,       Test Loss: 0.0066, Duration: 0:00:00.026776\n",
      "Epoch 539/1500, Train Loss: 0.0059,       Test Loss: 0.0060, Duration: 0:00:00.026456\n",
      "Epoch 540/1500, Train Loss: 0.0060,       Test Loss: 0.0060, Duration: 0:00:00.025862\n",
      "Epoch 541/1500, Train Loss: 0.0056,       Test Loss: 0.0053, Duration: 0:00:00.025897\n",
      "Epoch 542/1500, Train Loss: 0.0053,       Test Loss: 0.0054, Duration: 0:00:00.025756\n",
      "Epoch 543/1500, Train Loss: 0.0057,       Test Loss: 0.0057, Duration: 0:00:00.025942\n",
      "Epoch 544/1500, Train Loss: 0.0057,       Test Loss: 0.0063, Duration: 0:00:00.026458\n",
      "Epoch 545/1500, Train Loss: 0.0060,       Test Loss: 0.0058, Duration: 0:00:00.027066\n",
      "Epoch 546/1500, Train Loss: 0.0057,       Test Loss: 0.0059, Duration: 0:00:00.026182\n",
      "Epoch 547/1500, Train Loss: 0.0059,       Test Loss: 0.0080, Duration: 0:00:00.026209\n",
      "Epoch 548/1500, Train Loss: 0.0070,       Test Loss: 0.0077, Duration: 0:00:00.025896\n",
      "Epoch 549/1500, Train Loss: 0.0066,       Test Loss: 0.0072, Duration: 0:00:00.026474\n",
      "Epoch 550/1500, Train Loss: 0.0068,       Test Loss: 0.0079, Duration: 0:00:00.025723\n",
      "Epoch 551/1500, Train Loss: 0.0066,       Test Loss: 0.0087, Duration: 0:00:00.025882\n",
      "Epoch 552/1500, Train Loss: 0.0069,       Test Loss: 0.0080, Duration: 0:00:00.026384\n",
      "Epoch 553/1500, Train Loss: 0.0074,       Test Loss: 0.0095, Duration: 0:00:00.027304\n",
      "Epoch 554/1500, Train Loss: 0.0081,       Test Loss: 0.0095, Duration: 0:00:00.026065\n",
      "Epoch 555/1500, Train Loss: 0.0079,       Test Loss: 0.0094, Duration: 0:00:00.026187\n",
      "Epoch 556/1500, Train Loss: 0.0073,       Test Loss: 0.0093, Duration: 0:00:00.026087\n",
      "Epoch 557/1500, Train Loss: 0.0079,       Test Loss: 0.0093, Duration: 0:00:00.026399\n",
      "Epoch 558/1500, Train Loss: 0.0078,       Test Loss: 0.0088, Duration: 0:00:00.027066\n",
      "Epoch 559/1500, Train Loss: 0.0079,       Test Loss: 0.0109, Duration: 0:00:00.025997\n",
      "Epoch 560/1500, Train Loss: 0.0093,       Test Loss: 0.0136, Duration: 0:00:00.026759\n",
      "Epoch 561/1500, Train Loss: 0.0099,       Test Loss: 0.0111, Duration: 0:00:00.027244\n",
      "Epoch 562/1500, Train Loss: 0.0079,       Test Loss: 0.0075, Duration: 0:00:00.026236\n",
      "Epoch 563/1500, Train Loss: 0.0068,       Test Loss: 0.0072, Duration: 0:00:00.025731\n",
      "Epoch 564/1500, Train Loss: 0.0070,       Test Loss: 0.0065, Duration: 0:00:00.026174\n",
      "Epoch 565/1500, Train Loss: 0.0065,       Test Loss: 0.0071, Duration: 0:00:00.025690\n",
      "Epoch 566/1500, Train Loss: 0.0069,       Test Loss: 0.0071, Duration: 0:00:00.025917\n",
      "Epoch 567/1500, Train Loss: 0.0067,       Test Loss: 0.0071, Duration: 0:00:00.026049\n",
      "Epoch 568/1500, Train Loss: 0.0064,       Test Loss: 0.0068, Duration: 0:00:00.026771\n",
      "Epoch 569/1500, Train Loss: 0.0065,       Test Loss: 0.0071, Duration: 0:00:00.026832\n",
      "Epoch 570/1500, Train Loss: 0.0066,       Test Loss: 0.0070, Duration: 0:00:00.025856\n",
      "Epoch 571/1500, Train Loss: 0.0069,       Test Loss: 0.0064, Duration: 0:00:00.026059\n",
      "Epoch 572/1500, Train Loss: 0.0066,       Test Loss: 0.0060, Duration: 0:00:00.026357\n",
      "Epoch 573/1500, Train Loss: 0.0064,       Test Loss: 0.0054, Duration: 0:00:00.026269\n",
      "Epoch 574/1500, Train Loss: 0.0059,       Test Loss: 0.0052, Duration: 0:00:00.025963\n",
      "Epoch 575/1500, Train Loss: 0.0055,       Test Loss: 0.0042, Duration: 0:00:00.025958\n",
      "Epoch 576/1500, Train Loss: 0.0048,       Test Loss: 0.0043, Duration: 0:00:00.026885\n",
      "Epoch 577/1500, Train Loss: 0.0053,       Test Loss: 0.0052, Duration: 0:00:00.027491\n",
      "Epoch 578/1500, Train Loss: 0.0055,       Test Loss: 0.0050, Duration: 0:00:00.025990\n",
      "Epoch 579/1500, Train Loss: 0.0054,       Test Loss: 0.0061, Duration: 0:00:00.026713\n",
      "Epoch 580/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.025751\n",
      "Epoch 581/1500, Train Loss: 0.0058,       Test Loss: 0.0055, Duration: 0:00:00.025916\n",
      "Epoch 582/1500, Train Loss: 0.0056,       Test Loss: 0.0064, Duration: 0:00:00.025935\n",
      "Epoch 583/1500, Train Loss: 0.0063,       Test Loss: 0.0071, Duration: 0:00:00.025976\n",
      "Epoch 584/1500, Train Loss: 0.0060,       Test Loss: 0.0062, Duration: 0:00:00.026618\n",
      "Epoch 585/1500, Train Loss: 0.0059,       Test Loss: 0.0082, Duration: 0:00:00.027066\n",
      "Epoch 586/1500, Train Loss: 0.0067,       Test Loss: 0.0076, Duration: 0:00:00.026106\n",
      "Epoch 587/1500, Train Loss: 0.0074,       Test Loss: 0.0100, Duration: 0:00:00.025816\n",
      "Epoch 588/1500, Train Loss: 0.0073,       Test Loss: 0.0081, Duration: 0:00:00.025606\n",
      "Epoch 589/1500, Train Loss: 0.0076,       Test Loss: 0.0093, Duration: 0:00:00.026496\n",
      "Epoch 590/1500, Train Loss: 0.0081,       Test Loss: 0.0079, Duration: 0:00:00.026480\n",
      "Epoch 591/1500, Train Loss: 0.0071,       Test Loss: 0.0089, Duration: 0:00:00.025898\n",
      "Epoch 592/1500, Train Loss: 0.0078,       Test Loss: 0.0093, Duration: 0:00:00.026168\n",
      "Epoch 593/1500, Train Loss: 0.0080,       Test Loss: 0.0084, Duration: 0:00:00.027337\n",
      "Epoch 594/1500, Train Loss: 0.0065,       Test Loss: 0.0056, Duration: 0:00:00.026471\n",
      "Epoch 595/1500, Train Loss: 0.0058,       Test Loss: 0.0063, Duration: 0:00:00.026101\n",
      "Epoch 596/1500, Train Loss: 0.0061,       Test Loss: 0.0065, Duration: 0:00:00.027148\n",
      "Epoch 597/1500, Train Loss: 0.0062,       Test Loss: 0.0071, Duration: 0:00:00.025955\n",
      "Epoch 598/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.026275\n",
      "Epoch 599/1500, Train Loss: 0.0059,       Test Loss: 0.0069, Duration: 0:00:00.025979\n",
      "Epoch 600/1500, Train Loss: 0.0065,       Test Loss: 0.0079, Duration: 0:00:00.026652\n",
      "Epoch 601/1500, Train Loss: 0.0063,       Test Loss: 0.0078, Duration: 0:00:00.027279\n",
      "Epoch 602/1500, Train Loss: 0.0068,       Test Loss: 0.0082, Duration: 0:00:00.026564\n",
      "Epoch 603/1500, Train Loss: 0.0074,       Test Loss: 0.0070, Duration: 0:00:00.026084\n",
      "Epoch 604/1500, Train Loss: 0.0067,       Test Loss: 0.0065, Duration: 0:00:00.026194\n",
      "Epoch 605/1500, Train Loss: 0.0059,       Test Loss: 0.0059, Duration: 0:00:00.025960\n",
      "Epoch 606/1500, Train Loss: 0.0058,       Test Loss: 0.0068, Duration: 0:00:00.026064\n",
      "Epoch 607/1500, Train Loss: 0.0062,       Test Loss: 0.0065, Duration: 0:00:00.025817\n",
      "Epoch 608/1500, Train Loss: 0.0061,       Test Loss: 0.0065, Duration: 0:00:00.026869\n",
      "Epoch 609/1500, Train Loss: 0.0060,       Test Loss: 0.0068, Duration: 0:00:00.027315\n",
      "Epoch 610/1500, Train Loss: 0.0058,       Test Loss: 0.0062, Duration: 0:00:00.026134\n",
      "Epoch 611/1500, Train Loss: 0.0058,       Test Loss: 0.0059, Duration: 0:00:00.026018\n",
      "Epoch 612/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026178\n",
      "Epoch 613/1500, Train Loss: 0.0056,       Test Loss: 0.0059, Duration: 0:00:00.026124\n",
      "Epoch 614/1500, Train Loss: 0.0059,       Test Loss: 0.0059, Duration: 0:00:00.026196\n",
      "Epoch 615/1500, Train Loss: 0.0055,       Test Loss: 0.0061, Duration: 0:00:00.027123\n",
      "Epoch 616/1500, Train Loss: 0.0060,       Test Loss: 0.0068, Duration: 0:00:00.026932\n",
      "Epoch 617/1500, Train Loss: 0.0062,       Test Loss: 0.0073, Duration: 0:00:00.027492\n",
      "Epoch 618/1500, Train Loss: 0.0059,       Test Loss: 0.0065, Duration: 0:00:00.026103\n",
      "Epoch 619/1500, Train Loss: 0.0057,       Test Loss: 0.0067, Duration: 0:00:00.026165\n",
      "Epoch 620/1500, Train Loss: 0.0063,       Test Loss: 0.0073, Duration: 0:00:00.026035\n",
      "Epoch 621/1500, Train Loss: 0.0066,       Test Loss: 0.0096, Duration: 0:00:00.026047\n",
      "Epoch 622/1500, Train Loss: 0.0071,       Test Loss: 0.0077, Duration: 0:00:00.025882\n",
      "Epoch 623/1500, Train Loss: 0.0067,       Test Loss: 0.0075, Duration: 0:00:00.026281\n",
      "Epoch 624/1500, Train Loss: 0.0061,       Test Loss: 0.0061, Duration: 0:00:00.026522\n",
      "Epoch 625/1500, Train Loss: 0.0054,       Test Loss: 0.0052, Duration: 0:00:00.027284\n",
      "Epoch 626/1500, Train Loss: 0.0055,       Test Loss: 0.0058, Duration: 0:00:00.026232\n",
      "Epoch 627/1500, Train Loss: 0.0058,       Test Loss: 0.0062, Duration: 0:00:00.026168\n",
      "Epoch 628/1500, Train Loss: 0.0060,       Test Loss: 0.0072, Duration: 0:00:00.026445\n",
      "Epoch 629/1500, Train Loss: 0.0067,       Test Loss: 0.0084, Duration: 0:00:00.025976\n",
      "Epoch 630/1500, Train Loss: 0.0067,       Test Loss: 0.0068, Duration: 0:00:00.025958\n",
      "Epoch 631/1500, Train Loss: 0.0059,       Test Loss: 0.0069, Duration: 0:00:00.025888\n",
      "Epoch 632/1500, Train Loss: 0.0062,       Test Loss: 0.0063, Duration: 0:00:00.026635\n",
      "Epoch 633/1500, Train Loss: 0.0060,       Test Loss: 0.0077, Duration: 0:00:00.027009\n",
      "Epoch 634/1500, Train Loss: 0.0070,       Test Loss: 0.0088, Duration: 0:00:00.027148\n",
      "Epoch 635/1500, Train Loss: 0.0083,       Test Loss: 0.0074, Duration: 0:00:00.026393\n",
      "Epoch 636/1500, Train Loss: 0.0067,       Test Loss: 0.0074, Duration: 0:00:00.026316\n",
      "Epoch 637/1500, Train Loss: 0.0072,       Test Loss: 0.0069, Duration: 0:00:00.025942\n",
      "Epoch 638/1500, Train Loss: 0.0060,       Test Loss: 0.0066, Duration: 0:00:00.026050\n",
      "Epoch 639/1500, Train Loss: 0.0062,       Test Loss: 0.0073, Duration: 0:00:00.025881\n",
      "Epoch 640/1500, Train Loss: 0.0069,       Test Loss: 0.0086, Duration: 0:00:00.026920\n",
      "Epoch 641/1500, Train Loss: 0.0075,       Test Loss: 0.0086, Duration: 0:00:00.027185\n",
      "Epoch 642/1500, Train Loss: 0.0068,       Test Loss: 0.0076, Duration: 0:00:00.026164\n",
      "Epoch 643/1500, Train Loss: 0.0061,       Test Loss: 0.0059, Duration: 0:00:00.026092\n",
      "Epoch 644/1500, Train Loss: 0.0055,       Test Loss: 0.0053, Duration: 0:00:00.025885\n",
      "Epoch 645/1500, Train Loss: 0.0051,       Test Loss: 0.0049, Duration: 0:00:00.025990\n",
      "Epoch 646/1500, Train Loss: 0.0053,       Test Loss: 0.0051, Duration: 0:00:00.026042\n",
      "Epoch 647/1500, Train Loss: 0.0051,       Test Loss: 0.0052, Duration: 0:00:00.025950\n",
      "Epoch 648/1500, Train Loss: 0.0055,       Test Loss: 0.0054, Duration: 0:00:00.026584\n",
      "Epoch 649/1500, Train Loss: 0.0062,       Test Loss: 0.0071, Duration: 0:00:00.027025\n",
      "Epoch 650/1500, Train Loss: 0.0062,       Test Loss: 0.0060, Duration: 0:00:00.026333\n",
      "Epoch 651/1500, Train Loss: 0.0056,       Test Loss: 0.0062, Duration: 0:00:00.026473\n",
      "Epoch 652/1500, Train Loss: 0.0064,       Test Loss: 0.0071, Duration: 0:00:00.025944\n",
      "Epoch 653/1500, Train Loss: 0.0064,       Test Loss: 0.0056, Duration: 0:00:00.027183\n",
      "Epoch 654/1500, Train Loss: 0.0052,       Test Loss: 0.0053, Duration: 0:00:00.025911\n",
      "Epoch 655/1500, Train Loss: 0.0058,       Test Loss: 0.0062, Duration: 0:00:00.026224\n",
      "Epoch 656/1500, Train Loss: 0.0060,       Test Loss: 0.0065, Duration: 0:00:00.026083\n",
      "Epoch 657/1500, Train Loss: 0.0061,       Test Loss: 0.0072, Duration: 0:00:00.027613\n",
      "Epoch 658/1500, Train Loss: 0.0065,       Test Loss: 0.0070, Duration: 0:00:00.026023\n",
      "Epoch 659/1500, Train Loss: 0.0062,       Test Loss: 0.0071, Duration: 0:00:00.026707\n",
      "Epoch 660/1500, Train Loss: 0.0062,       Test Loss: 0.0070, Duration: 0:00:00.026143\n",
      "Epoch 661/1500, Train Loss: 0.0068,       Test Loss: 0.0098, Duration: 0:00:00.025969\n",
      "Epoch 662/1500, Train Loss: 0.0078,       Test Loss: 0.0113, Duration: 0:00:00.025834\n",
      "Epoch 663/1500, Train Loss: 0.0096,       Test Loss: 0.0173, Duration: 0:00:00.026154\n",
      "Epoch 664/1500, Train Loss: 0.0116,       Test Loss: 0.0095, Duration: 0:00:00.026514\n",
      "Epoch 665/1500, Train Loss: 0.0078,       Test Loss: 0.0082, Duration: 0:00:00.027122\n",
      "Epoch 666/1500, Train Loss: 0.0064,       Test Loss: 0.0067, Duration: 0:00:00.026710\n",
      "Epoch 667/1500, Train Loss: 0.0062,       Test Loss: 0.0076, Duration: 0:00:00.026222\n",
      "Epoch 668/1500, Train Loss: 0.0066,       Test Loss: 0.0078, Duration: 0:00:00.026048\n",
      "Epoch 669/1500, Train Loss: 0.0067,       Test Loss: 0.0081, Duration: 0:00:00.026026\n",
      "Epoch 670/1500, Train Loss: 0.0065,       Test Loss: 0.0066, Duration: 0:00:00.026086\n",
      "Epoch 671/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026079\n",
      "Epoch 672/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.028059\n",
      "Epoch 673/1500, Train Loss: 0.0050,       Test Loss: 0.0045, Duration: 0:00:00.027205\n",
      "Epoch 674/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.026399\n",
      "Epoch 675/1500, Train Loss: 0.0051,       Test Loss: 0.0049, Duration: 0:00:00.025818\n",
      "Epoch 676/1500, Train Loss: 0.0050,       Test Loss: 0.0047, Duration: 0:00:00.026255\n",
      "Epoch 677/1500, Train Loss: 0.0047,       Test Loss: 0.0046, Duration: 0:00:00.025559\n",
      "Epoch 678/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.025641\n",
      "Epoch 679/1500, Train Loss: 0.0056,       Test Loss: 0.0067, Duration: 0:00:00.025482\n",
      "Epoch 680/1500, Train Loss: 0.0069,       Test Loss: 0.0084, Duration: 0:00:00.026855\n",
      "Epoch 681/1500, Train Loss: 0.0070,       Test Loss: 0.0070, Duration: 0:00:00.027475\n",
      "Epoch 682/1500, Train Loss: 0.0065,       Test Loss: 0.0069, Duration: 0:00:00.026294\n",
      "Epoch 683/1500, Train Loss: 0.0061,       Test Loss: 0.0066, Duration: 0:00:00.026236\n",
      "Epoch 684/1500, Train Loss: 0.0066,       Test Loss: 0.0072, Duration: 0:00:00.025946\n",
      "Epoch 685/1500, Train Loss: 0.0063,       Test Loss: 0.0069, Duration: 0:00:00.025929\n",
      "Epoch 686/1500, Train Loss: 0.0057,       Test Loss: 0.0053, Duration: 0:00:00.025832\n",
      "Epoch 687/1500, Train Loss: 0.0055,       Test Loss: 0.0053, Duration: 0:00:00.025796\n",
      "Epoch 688/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026401\n",
      "Epoch 689/1500, Train Loss: 0.0050,       Test Loss: 0.0055, Duration: 0:00:00.027402\n",
      "Epoch 690/1500, Train Loss: 0.0052,       Test Loss: 0.0055, Duration: 0:00:00.026231\n",
      "Epoch 691/1500, Train Loss: 0.0051,       Test Loss: 0.0055, Duration: 0:00:00.027215\n",
      "Epoch 692/1500, Train Loss: 0.0055,       Test Loss: 0.0066, Duration: 0:00:00.026055\n",
      "Epoch 693/1500, Train Loss: 0.0053,       Test Loss: 0.0055, Duration: 0:00:00.026074\n",
      "Epoch 694/1500, Train Loss: 0.0057,       Test Loss: 0.0067, Duration: 0:00:00.025697\n",
      "Epoch 695/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.025932\n",
      "Epoch 696/1500, Train Loss: 0.0061,       Test Loss: 0.0068, Duration: 0:00:00.026628\n",
      "Epoch 697/1500, Train Loss: 0.0061,       Test Loss: 0.0062, Duration: 0:00:00.027438\n",
      "Epoch 698/1500, Train Loss: 0.0062,       Test Loss: 0.0072, Duration: 0:00:00.026030\n",
      "Epoch 699/1500, Train Loss: 0.0061,       Test Loss: 0.0058, Duration: 0:00:00.026204\n",
      "Epoch 700/1500, Train Loss: 0.0057,       Test Loss: 0.0065, Duration: 0:00:00.025950\n",
      "Epoch 701/1500, Train Loss: 0.0059,       Test Loss: 0.0052, Duration: 0:00:00.026006\n",
      "Epoch 702/1500, Train Loss: 0.0055,       Test Loss: 0.0063, Duration: 0:00:00.025958\n",
      "Epoch 703/1500, Train Loss: 0.0059,       Test Loss: 0.0072, Duration: 0:00:00.026208\n",
      "Epoch 704/1500, Train Loss: 0.0064,       Test Loss: 0.0080, Duration: 0:00:00.026856\n",
      "Epoch 705/1500, Train Loss: 0.0070,       Test Loss: 0.0093, Duration: 0:00:00.027438\n",
      "Epoch 706/1500, Train Loss: 0.0079,       Test Loss: 0.0102, Duration: 0:00:00.026392\n",
      "Epoch 707/1500, Train Loss: 0.0077,       Test Loss: 0.0081, Duration: 0:00:00.026166\n",
      "Epoch 708/1500, Train Loss: 0.0078,       Test Loss: 0.0106, Duration: 0:00:00.026158\n",
      "Epoch 709/1500, Train Loss: 0.0082,       Test Loss: 0.0115, Duration: 0:00:00.026223\n",
      "Epoch 710/1500, Train Loss: 0.0093,       Test Loss: 0.0120, Duration: 0:00:00.026901\n",
      "Epoch 711/1500, Train Loss: 0.0096,       Test Loss: 0.0134, Duration: 0:00:00.025934\n",
      "Epoch 712/1500, Train Loss: 0.0090,       Test Loss: 0.0096, Duration: 0:00:00.026929\n",
      "Epoch 713/1500, Train Loss: 0.0073,       Test Loss: 0.0074, Duration: 0:00:00.027233\n",
      "Epoch 714/1500, Train Loss: 0.0065,       Test Loss: 0.0069, Duration: 0:00:00.026357\n",
      "Epoch 715/1500, Train Loss: 0.0063,       Test Loss: 0.0060, Duration: 0:00:00.026189\n",
      "Epoch 716/1500, Train Loss: 0.0059,       Test Loss: 0.0067, Duration: 0:00:00.026147\n",
      "Epoch 717/1500, Train Loss: 0.0062,       Test Loss: 0.0076, Duration: 0:00:00.026004\n",
      "Epoch 718/1500, Train Loss: 0.0075,       Test Loss: 0.0104, Duration: 0:00:00.026006\n",
      "Epoch 719/1500, Train Loss: 0.0079,       Test Loss: 0.0098, Duration: 0:00:00.026178\n",
      "Epoch 720/1500, Train Loss: 0.0083,       Test Loss: 0.0111, Duration: 0:00:00.026562\n",
      "Epoch 721/1500, Train Loss: 0.0084,       Test Loss: 0.0083, Duration: 0:00:00.027203\n",
      "Epoch 722/1500, Train Loss: 0.0073,       Test Loss: 0.0063, Duration: 0:00:00.026221\n",
      "Epoch 723/1500, Train Loss: 0.0056,       Test Loss: 0.0052, Duration: 0:00:00.026332\n",
      "Epoch 724/1500, Train Loss: 0.0055,       Test Loss: 0.0059, Duration: 0:00:00.026168\n",
      "Epoch 725/1500, Train Loss: 0.0055,       Test Loss: 0.0046, Duration: 0:00:00.026199\n",
      "Epoch 726/1500, Train Loss: 0.0050,       Test Loss: 0.0047, Duration: 0:00:00.025901\n",
      "Epoch 727/1500, Train Loss: 0.0052,       Test Loss: 0.0052, Duration: 0:00:00.026030\n",
      "Epoch 728/1500, Train Loss: 0.0053,       Test Loss: 0.0052, Duration: 0:00:00.026639\n",
      "Epoch 729/1500, Train Loss: 0.0052,       Test Loss: 0.0048, Duration: 0:00:00.028076\n",
      "Epoch 730/1500, Train Loss: 0.0053,       Test Loss: 0.0048, Duration: 0:00:00.026028\n",
      "Epoch 731/1500, Train Loss: 0.0053,       Test Loss: 0.0045, Duration: 0:00:00.026296\n",
      "Epoch 732/1500, Train Loss: 0.0055,       Test Loss: 0.0048, Duration: 0:00:00.026108\n",
      "Epoch 733/1500, Train Loss: 0.0052,       Test Loss: 0.0045, Duration: 0:00:00.026236\n",
      "Epoch 734/1500, Train Loss: 0.0048,       Test Loss: 0.0041, Duration: 0:00:00.026004\n",
      "Epoch 735/1500, Train Loss: 0.0050,       Test Loss: 0.0045, Duration: 0:00:00.026090\n",
      "Epoch 736/1500, Train Loss: 0.0047,       Test Loss: 0.0039, Duration: 0:00:00.026630\n",
      "Epoch 737/1500, Train Loss: 0.0046,       Test Loss: 0.0042, Duration: 0:00:00.026903\n",
      "Epoch 738/1500, Train Loss: 0.0047,       Test Loss: 0.0044, Duration: 0:00:00.026220\n",
      "Epoch 739/1500, Train Loss: 0.0051,       Test Loss: 0.0044, Duration: 0:00:00.026447\n",
      "Epoch 740/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.026191\n",
      "Epoch 741/1500, Train Loss: 0.0055,       Test Loss: 0.0062, Duration: 0:00:00.025693\n",
      "Epoch 742/1500, Train Loss: 0.0058,       Test Loss: 0.0067, Duration: 0:00:00.026088\n",
      "Epoch 743/1500, Train Loss: 0.0059,       Test Loss: 0.0070, Duration: 0:00:00.026078\n",
      "Epoch 744/1500, Train Loss: 0.0062,       Test Loss: 0.0072, Duration: 0:00:00.026737\n",
      "Epoch 745/1500, Train Loss: 0.0062,       Test Loss: 0.0077, Duration: 0:00:00.027237\n",
      "Epoch 746/1500, Train Loss: 0.0067,       Test Loss: 0.0073, Duration: 0:00:00.026617\n",
      "Epoch 747/1500, Train Loss: 0.0064,       Test Loss: 0.0067, Duration: 0:00:00.026591\n",
      "Epoch 748/1500, Train Loss: 0.0056,       Test Loss: 0.0062, Duration: 0:00:00.026848\n",
      "Epoch 749/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.025869\n",
      "Epoch 750/1500, Train Loss: 0.0056,       Test Loss: 0.0067, Duration: 0:00:00.025870\n",
      "Epoch 751/1500, Train Loss: 0.0059,       Test Loss: 0.0062, Duration: 0:00:00.026169\n",
      "Epoch 752/1500, Train Loss: 0.0057,       Test Loss: 0.0055, Duration: 0:00:00.026748\n",
      "Epoch 753/1500, Train Loss: 0.0054,       Test Loss: 0.0060, Duration: 0:00:00.026929\n",
      "Epoch 754/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.025948\n",
      "Epoch 755/1500, Train Loss: 0.0055,       Test Loss: 0.0054, Duration: 0:00:00.026057\n",
      "Epoch 756/1500, Train Loss: 0.0057,       Test Loss: 0.0057, Duration: 0:00:00.025949\n",
      "Epoch 757/1500, Train Loss: 0.0057,       Test Loss: 0.0062, Duration: 0:00:00.026205\n",
      "Epoch 758/1500, Train Loss: 0.0060,       Test Loss: 0.0072, Duration: 0:00:00.026050\n",
      "Epoch 759/1500, Train Loss: 0.0064,       Test Loss: 0.0057, Duration: 0:00:00.026190\n",
      "Epoch 760/1500, Train Loss: 0.0058,       Test Loss: 0.0057, Duration: 0:00:00.026625\n",
      "Epoch 761/1500, Train Loss: 0.0053,       Test Loss: 0.0057, Duration: 0:00:00.027381\n",
      "Epoch 762/1500, Train Loss: 0.0052,       Test Loss: 0.0052, Duration: 0:00:00.026261\n",
      "Epoch 763/1500, Train Loss: 0.0054,       Test Loss: 0.0055, Duration: 0:00:00.026375\n",
      "Epoch 764/1500, Train Loss: 0.0054,       Test Loss: 0.0055, Duration: 0:00:00.026038\n",
      "Epoch 765/1500, Train Loss: 0.0055,       Test Loss: 0.0061, Duration: 0:00:00.026219\n",
      "Epoch 766/1500, Train Loss: 0.0059,       Test Loss: 0.0061, Duration: 0:00:00.026580\n",
      "Epoch 767/1500, Train Loss: 0.0060,       Test Loss: 0.0074, Duration: 0:00:00.026592\n",
      "Epoch 768/1500, Train Loss: 0.0068,       Test Loss: 0.0090, Duration: 0:00:00.026322\n",
      "Epoch 769/1500, Train Loss: 0.0076,       Test Loss: 0.0100, Duration: 0:00:00.027428\n",
      "Epoch 770/1500, Train Loss: 0.0073,       Test Loss: 0.0092, Duration: 0:00:00.026343\n",
      "Epoch 771/1500, Train Loss: 0.0071,       Test Loss: 0.0089, Duration: 0:00:00.026130\n",
      "Epoch 772/1500, Train Loss: 0.0077,       Test Loss: 0.0100, Duration: 0:00:00.025903\n",
      "Epoch 773/1500, Train Loss: 0.0074,       Test Loss: 0.0107, Duration: 0:00:00.025847\n",
      "Epoch 774/1500, Train Loss: 0.0086,       Test Loss: 0.0088, Duration: 0:00:00.026039\n",
      "Epoch 775/1500, Train Loss: 0.0075,       Test Loss: 0.0086, Duration: 0:00:00.025833\n",
      "Epoch 776/1500, Train Loss: 0.0077,       Test Loss: 0.0095, Duration: 0:00:00.026622\n",
      "Epoch 777/1500, Train Loss: 0.0081,       Test Loss: 0.0112, Duration: 0:00:00.027262\n",
      "Epoch 778/1500, Train Loss: 0.0082,       Test Loss: 0.0098, Duration: 0:00:00.026539\n",
      "Epoch 779/1500, Train Loss: 0.0085,       Test Loss: 0.0113, Duration: 0:00:00.026148\n",
      "Epoch 780/1500, Train Loss: 0.0081,       Test Loss: 0.0095, Duration: 0:00:00.026469\n",
      "Epoch 781/1500, Train Loss: 0.0073,       Test Loss: 0.0099, Duration: 0:00:00.025902\n",
      "Epoch 782/1500, Train Loss: 0.0077,       Test Loss: 0.0091, Duration: 0:00:00.026347\n",
      "Epoch 783/1500, Train Loss: 0.0071,       Test Loss: 0.0087, Duration: 0:00:00.025874\n",
      "Epoch 784/1500, Train Loss: 0.0080,       Test Loss: 0.0102, Duration: 0:00:00.026180\n",
      "Epoch 785/1500, Train Loss: 0.0091,       Test Loss: 0.0077, Duration: 0:00:00.027447\n",
      "Epoch 786/1500, Train Loss: 0.0070,       Test Loss: 0.0082, Duration: 0:00:00.027089\n",
      "Epoch 787/1500, Train Loss: 0.0067,       Test Loss: 0.0068, Duration: 0:00:00.026296\n",
      "Epoch 788/1500, Train Loss: 0.0062,       Test Loss: 0.0074, Duration: 0:00:00.026259\n",
      "Epoch 789/1500, Train Loss: 0.0070,       Test Loss: 0.0080, Duration: 0:00:00.026122\n",
      "Epoch 790/1500, Train Loss: 0.0075,       Test Loss: 0.0074, Duration: 0:00:00.025724\n",
      "Epoch 791/1500, Train Loss: 0.0071,       Test Loss: 0.0069, Duration: 0:00:00.026095\n",
      "Epoch 792/1500, Train Loss: 0.0064,       Test Loss: 0.0071, Duration: 0:00:00.026600\n",
      "Epoch 793/1500, Train Loss: 0.0072,       Test Loss: 0.0072, Duration: 0:00:00.027023\n",
      "Epoch 794/1500, Train Loss: 0.0065,       Test Loss: 0.0067, Duration: 0:00:00.025917\n",
      "Epoch 795/1500, Train Loss: 0.0067,       Test Loss: 0.0067, Duration: 0:00:00.026254\n",
      "Epoch 796/1500, Train Loss: 0.0072,       Test Loss: 0.0086, Duration: 0:00:00.025753\n",
      "Epoch 797/1500, Train Loss: 0.0077,       Test Loss: 0.0082, Duration: 0:00:00.026170\n",
      "Epoch 798/1500, Train Loss: 0.0075,       Test Loss: 0.0074, Duration: 0:00:00.025837\n",
      "Epoch 799/1500, Train Loss: 0.0074,       Test Loss: 0.0077, Duration: 0:00:00.026124\n",
      "Epoch 800/1500, Train Loss: 0.0075,       Test Loss: 0.0073, Duration: 0:00:00.026287\n",
      "Epoch 801/1500, Train Loss: 0.0068,       Test Loss: 0.0061, Duration: 0:00:00.027244\n",
      "Epoch 802/1500, Train Loss: 0.0061,       Test Loss: 0.0054, Duration: 0:00:00.026168\n",
      "Epoch 803/1500, Train Loss: 0.0057,       Test Loss: 0.0046, Duration: 0:00:00.026234\n",
      "Epoch 804/1500, Train Loss: 0.0051,       Test Loss: 0.0049, Duration: 0:00:00.025816\n",
      "Epoch 805/1500, Train Loss: 0.0054,       Test Loss: 0.0052, Duration: 0:00:00.027194\n",
      "Epoch 806/1500, Train Loss: 0.0051,       Test Loss: 0.0047, Duration: 0:00:00.026227\n",
      "Epoch 807/1500, Train Loss: 0.0050,       Test Loss: 0.0043, Duration: 0:00:00.026086\n",
      "Epoch 808/1500, Train Loss: 0.0045,       Test Loss: 0.0041, Duration: 0:00:00.026364\n",
      "Epoch 809/1500, Train Loss: 0.0046,       Test Loss: 0.0040, Duration: 0:00:00.026892\n",
      "Epoch 810/1500, Train Loss: 0.0047,       Test Loss: 0.0045, Duration: 0:00:00.026574\n",
      "Epoch 811/1500, Train Loss: 0.0051,       Test Loss: 0.0057, Duration: 0:00:00.026174\n",
      "Epoch 812/1500, Train Loss: 0.0058,       Test Loss: 0.0065, Duration: 0:00:00.026018\n",
      "Epoch 813/1500, Train Loss: 0.0057,       Test Loss: 0.0053, Duration: 0:00:00.025992\n",
      "Epoch 814/1500, Train Loss: 0.0057,       Test Loss: 0.0058, Duration: 0:00:00.026221\n",
      "Epoch 815/1500, Train Loss: 0.0057,       Test Loss: 0.0070, Duration: 0:00:00.026014\n",
      "Epoch 816/1500, Train Loss: 0.0067,       Test Loss: 0.0064, Duration: 0:00:00.026923\n",
      "Epoch 817/1500, Train Loss: 0.0064,       Test Loss: 0.0066, Duration: 0:00:00.027027\n",
      "Epoch 818/1500, Train Loss: 0.0064,       Test Loss: 0.0067, Duration: 0:00:00.026470\n",
      "Epoch 819/1500, Train Loss: 0.0062,       Test Loss: 0.0065, Duration: 0:00:00.026201\n",
      "Epoch 820/1500, Train Loss: 0.0061,       Test Loss: 0.0070, Duration: 0:00:00.026314\n",
      "Epoch 821/1500, Train Loss: 0.0061,       Test Loss: 0.0060, Duration: 0:00:00.026041\n",
      "Epoch 822/1500, Train Loss: 0.0059,       Test Loss: 0.0060, Duration: 0:00:00.026086\n",
      "Epoch 823/1500, Train Loss: 0.0055,       Test Loss: 0.0060, Duration: 0:00:00.026176\n",
      "Epoch 824/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.027225\n",
      "Epoch 825/1500, Train Loss: 0.0058,       Test Loss: 0.0060, Duration: 0:00:00.027223\n",
      "Epoch 826/1500, Train Loss: 0.0054,       Test Loss: 0.0051, Duration: 0:00:00.026346\n",
      "Epoch 827/1500, Train Loss: 0.0052,       Test Loss: 0.0048, Duration: 0:00:00.026240\n",
      "Epoch 828/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.025984\n",
      "Epoch 829/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.026132\n",
      "Epoch 830/1500, Train Loss: 0.0055,       Test Loss: 0.0067, Duration: 0:00:00.025685\n",
      "Epoch 831/1500, Train Loss: 0.0061,       Test Loss: 0.0063, Duration: 0:00:00.025893\n",
      "Epoch 832/1500, Train Loss: 0.0057,       Test Loss: 0.0063, Duration: 0:00:00.026541\n",
      "Epoch 833/1500, Train Loss: 0.0055,       Test Loss: 0.0050, Duration: 0:00:00.027865\n",
      "Epoch 834/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.026173\n",
      "Epoch 835/1500, Train Loss: 0.0052,       Test Loss: 0.0059, Duration: 0:00:00.026280\n",
      "Epoch 836/1500, Train Loss: 0.0053,       Test Loss: 0.0058, Duration: 0:00:00.025912\n",
      "Epoch 837/1500, Train Loss: 0.0053,       Test Loss: 0.0057, Duration: 0:00:00.026209\n",
      "Epoch 838/1500, Train Loss: 0.0052,       Test Loss: 0.0049, Duration: 0:00:00.025710\n",
      "Epoch 839/1500, Train Loss: 0.0050,       Test Loss: 0.0057, Duration: 0:00:00.026363\n",
      "Epoch 840/1500, Train Loss: 0.0054,       Test Loss: 0.0060, Duration: 0:00:00.026825\n",
      "Epoch 841/1500, Train Loss: 0.0065,       Test Loss: 0.0087, Duration: 0:00:00.027546\n",
      "Epoch 842/1500, Train Loss: 0.0074,       Test Loss: 0.0097, Duration: 0:00:00.026660\n",
      "Epoch 843/1500, Train Loss: 0.0079,       Test Loss: 0.0095, Duration: 0:00:00.026120\n",
      "Epoch 844/1500, Train Loss: 0.0083,       Test Loss: 0.0094, Duration: 0:00:00.026052\n",
      "Epoch 845/1500, Train Loss: 0.0083,       Test Loss: 0.0084, Duration: 0:00:00.026068\n",
      "Epoch 846/1500, Train Loss: 0.0069,       Test Loss: 0.0063, Duration: 0:00:00.026018\n",
      "Epoch 847/1500, Train Loss: 0.0063,       Test Loss: 0.0063, Duration: 0:00:00.025980\n",
      "Epoch 848/1500, Train Loss: 0.0061,       Test Loss: 0.0057, Duration: 0:00:00.026773\n",
      "Epoch 849/1500, Train Loss: 0.0055,       Test Loss: 0.0051, Duration: 0:00:00.027210\n",
      "Epoch 850/1500, Train Loss: 0.0055,       Test Loss: 0.0058, Duration: 0:00:00.026374\n",
      "Epoch 851/1500, Train Loss: 0.0053,       Test Loss: 0.0063, Duration: 0:00:00.025820\n",
      "Epoch 852/1500, Train Loss: 0.0060,       Test Loss: 0.0078, Duration: 0:00:00.026442\n",
      "Epoch 853/1500, Train Loss: 0.0065,       Test Loss: 0.0067, Duration: 0:00:00.025895\n",
      "Epoch 854/1500, Train Loss: 0.0062,       Test Loss: 0.0074, Duration: 0:00:00.026253\n",
      "Epoch 855/1500, Train Loss: 0.0064,       Test Loss: 0.0073, Duration: 0:00:00.025950\n",
      "Epoch 856/1500, Train Loss: 0.0058,       Test Loss: 0.0061, Duration: 0:00:00.026950\n",
      "Epoch 857/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.027624\n",
      "Epoch 858/1500, Train Loss: 0.0062,       Test Loss: 0.0087, Duration: 0:00:00.026512\n",
      "Epoch 859/1500, Train Loss: 0.0069,       Test Loss: 0.0085, Duration: 0:00:00.026216\n",
      "Epoch 860/1500, Train Loss: 0.0065,       Test Loss: 0.0069, Duration: 0:00:00.026077\n",
      "Epoch 861/1500, Train Loss: 0.0062,       Test Loss: 0.0078, Duration: 0:00:00.026759\n",
      "Epoch 862/1500, Train Loss: 0.0061,       Test Loss: 0.0064, Duration: 0:00:00.026238\n",
      "Epoch 863/1500, Train Loss: 0.0060,       Test Loss: 0.0067, Duration: 0:00:00.026029\n",
      "Epoch 864/1500, Train Loss: 0.0059,       Test Loss: 0.0061, Duration: 0:00:00.027041\n",
      "Epoch 865/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.026911\n",
      "Epoch 866/1500, Train Loss: 0.0053,       Test Loss: 0.0051, Duration: 0:00:00.025781\n",
      "Epoch 867/1500, Train Loss: 0.0050,       Test Loss: 0.0042, Duration: 0:00:00.026020\n",
      "Epoch 868/1500, Train Loss: 0.0049,       Test Loss: 0.0042, Duration: 0:00:00.026340\n",
      "Epoch 869/1500, Train Loss: 0.0048,       Test Loss: 0.0053, Duration: 0:00:00.026292\n",
      "Epoch 870/1500, Train Loss: 0.0055,       Test Loss: 0.0050, Duration: 0:00:00.025573\n",
      "Epoch 871/1500, Train Loss: 0.0052,       Test Loss: 0.0050, Duration: 0:00:00.026062\n",
      "Epoch 872/1500, Train Loss: 0.0055,       Test Loss: 0.0060, Duration: 0:00:00.026585\n",
      "Epoch 873/1500, Train Loss: 0.0058,       Test Loss: 0.0052, Duration: 0:00:00.027631\n",
      "Epoch 874/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026254\n",
      "Epoch 875/1500, Train Loss: 0.0052,       Test Loss: 0.0053, Duration: 0:00:00.026024\n",
      "Epoch 876/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.026369\n",
      "Epoch 877/1500, Train Loss: 0.0051,       Test Loss: 0.0049, Duration: 0:00:00.026226\n",
      "Epoch 878/1500, Train Loss: 0.0054,       Test Loss: 0.0053, Duration: 0:00:00.026071\n",
      "Epoch 879/1500, Train Loss: 0.0051,       Test Loss: 0.0052, Duration: 0:00:00.026136\n",
      "Epoch 880/1500, Train Loss: 0.0051,       Test Loss: 0.0053, Duration: 0:00:00.027173\n",
      "Epoch 881/1500, Train Loss: 0.0051,       Test Loss: 0.0049, Duration: 0:00:00.027724\n",
      "Epoch 882/1500, Train Loss: 0.0049,       Test Loss: 0.0044, Duration: 0:00:00.026400\n",
      "Epoch 883/1500, Train Loss: 0.0052,       Test Loss: 0.0050, Duration: 0:00:00.025686\n",
      "Epoch 884/1500, Train Loss: 0.0050,       Test Loss: 0.0043, Duration: 0:00:00.026408\n",
      "Epoch 885/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.025978\n",
      "Epoch 886/1500, Train Loss: 0.0048,       Test Loss: 0.0049, Duration: 0:00:00.026078\n",
      "Epoch 887/1500, Train Loss: 0.0051,       Test Loss: 0.0058, Duration: 0:00:00.025993\n",
      "Epoch 888/1500, Train Loss: 0.0060,       Test Loss: 0.0062, Duration: 0:00:00.026996\n",
      "Epoch 889/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.027214\n",
      "Epoch 890/1500, Train Loss: 0.0060,       Test Loss: 0.0059, Duration: 0:00:00.026397\n",
      "Epoch 891/1500, Train Loss: 0.0054,       Test Loss: 0.0052, Duration: 0:00:00.026164\n",
      "Epoch 892/1500, Train Loss: 0.0053,       Test Loss: 0.0055, Duration: 0:00:00.026290\n",
      "Epoch 893/1500, Train Loss: 0.0056,       Test Loss: 0.0054, Duration: 0:00:00.026127\n",
      "Epoch 894/1500, Train Loss: 0.0050,       Test Loss: 0.0054, Duration: 0:00:00.025817\n",
      "Epoch 895/1500, Train Loss: 0.0058,       Test Loss: 0.0067, Duration: 0:00:00.025807\n",
      "Epoch 896/1500, Train Loss: 0.0060,       Test Loss: 0.0071, Duration: 0:00:00.026689\n",
      "Epoch 897/1500, Train Loss: 0.0063,       Test Loss: 0.0074, Duration: 0:00:00.027451\n",
      "Epoch 898/1500, Train Loss: 0.0058,       Test Loss: 0.0057, Duration: 0:00:00.026286\n",
      "Epoch 899/1500, Train Loss: 0.0053,       Test Loss: 0.0049, Duration: 0:00:00.027175\n",
      "Epoch 900/1500, Train Loss: 0.0050,       Test Loss: 0.0051, Duration: 0:00:00.026097\n",
      "Epoch 901/1500, Train Loss: 0.0051,       Test Loss: 0.0047, Duration: 0:00:00.026090\n",
      "Epoch 902/1500, Train Loss: 0.0050,       Test Loss: 0.0053, Duration: 0:00:00.025941\n",
      "Epoch 903/1500, Train Loss: 0.0051,       Test Loss: 0.0058, Duration: 0:00:00.026176\n",
      "Epoch 904/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.026715\n",
      "Epoch 905/1500, Train Loss: 0.0056,       Test Loss: 0.0060, Duration: 0:00:00.027672\n",
      "Epoch 906/1500, Train Loss: 0.0054,       Test Loss: 0.0064, Duration: 0:00:00.026040\n",
      "Epoch 907/1500, Train Loss: 0.0065,       Test Loss: 0.0088, Duration: 0:00:00.026412\n",
      "Epoch 908/1500, Train Loss: 0.0070,       Test Loss: 0.0073, Duration: 0:00:00.025925\n",
      "Epoch 909/1500, Train Loss: 0.0068,       Test Loss: 0.0058, Duration: 0:00:00.026288\n",
      "Epoch 910/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.025842\n",
      "Epoch 911/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.026310\n",
      "Epoch 912/1500, Train Loss: 0.0052,       Test Loss: 0.0054, Duration: 0:00:00.026568\n",
      "Epoch 913/1500, Train Loss: 0.0052,       Test Loss: 0.0053, Duration: 0:00:00.027100\n",
      "Epoch 914/1500, Train Loss: 0.0054,       Test Loss: 0.0053, Duration: 0:00:00.025934\n",
      "Epoch 915/1500, Train Loss: 0.0049,       Test Loss: 0.0051, Duration: 0:00:00.026111\n",
      "Epoch 916/1500, Train Loss: 0.0052,       Test Loss: 0.0056, Duration: 0:00:00.026059\n",
      "Epoch 917/1500, Train Loss: 0.0053,       Test Loss: 0.0055, Duration: 0:00:00.025683\n",
      "Epoch 918/1500, Train Loss: 0.0056,       Test Loss: 0.0058, Duration: 0:00:00.026786\n",
      "Epoch 919/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026105\n",
      "Epoch 920/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026652\n",
      "Epoch 921/1500, Train Loss: 0.0053,       Test Loss: 0.0061, Duration: 0:00:00.027428\n",
      "Epoch 922/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.026781\n",
      "Epoch 923/1500, Train Loss: 0.0062,       Test Loss: 0.0068, Duration: 0:00:00.026051\n",
      "Epoch 924/1500, Train Loss: 0.0068,       Test Loss: 0.0081, Duration: 0:00:00.026335\n",
      "Epoch 925/1500, Train Loss: 0.0068,       Test Loss: 0.0075, Duration: 0:00:00.025904\n",
      "Epoch 926/1500, Train Loss: 0.0085,       Test Loss: 0.0139, Duration: 0:00:00.026503\n",
      "Epoch 927/1500, Train Loss: 0.0104,       Test Loss: 0.0066, Duration: 0:00:00.025808\n",
      "Epoch 928/1500, Train Loss: 0.0058,       Test Loss: 0.0065, Duration: 0:00:00.026584\n",
      "Epoch 929/1500, Train Loss: 0.0056,       Test Loss: 0.0068, Duration: 0:00:00.027439\n",
      "Epoch 930/1500, Train Loss: 0.0057,       Test Loss: 0.0056, Duration: 0:00:00.026211\n",
      "Epoch 931/1500, Train Loss: 0.0051,       Test Loss: 0.0055, Duration: 0:00:00.027014\n",
      "Epoch 932/1500, Train Loss: 0.0053,       Test Loss: 0.0064, Duration: 0:00:00.027165\n",
      "Epoch 933/1500, Train Loss: 0.0059,       Test Loss: 0.0075, Duration: 0:00:00.026084\n",
      "Epoch 934/1500, Train Loss: 0.0066,       Test Loss: 0.0070, Duration: 0:00:00.025813\n",
      "Epoch 935/1500, Train Loss: 0.0064,       Test Loss: 0.0073, Duration: 0:00:00.025984\n",
      "Epoch 936/1500, Train Loss: 0.0067,       Test Loss: 0.0078, Duration: 0:00:00.026626\n",
      "Epoch 937/1500, Train Loss: 0.0063,       Test Loss: 0.0074, Duration: 0:00:00.028317\n",
      "Epoch 938/1500, Train Loss: 0.0066,       Test Loss: 0.0055, Duration: 0:00:00.026346\n",
      "Epoch 939/1500, Train Loss: 0.0054,       Test Loss: 0.0058, Duration: 0:00:00.026440\n",
      "Epoch 940/1500, Train Loss: 0.0055,       Test Loss: 0.0065, Duration: 0:00:00.025960\n",
      "Epoch 941/1500, Train Loss: 0.0057,       Test Loss: 0.0066, Duration: 0:00:00.026380\n",
      "Epoch 942/1500, Train Loss: 0.0059,       Test Loss: 0.0075, Duration: 0:00:00.025577\n",
      "Epoch 943/1500, Train Loss: 0.0067,       Test Loss: 0.0095, Duration: 0:00:00.026129\n",
      "Epoch 944/1500, Train Loss: 0.0077,       Test Loss: 0.0093, Duration: 0:00:00.026782\n",
      "Epoch 945/1500, Train Loss: 0.0071,       Test Loss: 0.0082, Duration: 0:00:00.027319\n",
      "Epoch 946/1500, Train Loss: 0.0062,       Test Loss: 0.0065, Duration: 0:00:00.026452\n",
      "Epoch 947/1500, Train Loss: 0.0058,       Test Loss: 0.0066, Duration: 0:00:00.026157\n",
      "Epoch 948/1500, Train Loss: 0.0057,       Test Loss: 0.0067, Duration: 0:00:00.025957\n",
      "Epoch 949/1500, Train Loss: 0.0062,       Test Loss: 0.0082, Duration: 0:00:00.026388\n",
      "Epoch 950/1500, Train Loss: 0.0071,       Test Loss: 0.0077, Duration: 0:00:00.026077\n",
      "Epoch 951/1500, Train Loss: 0.0070,       Test Loss: 0.0105, Duration: 0:00:00.026022\n",
      "Epoch 952/1500, Train Loss: 0.0089,       Test Loss: 0.0101, Duration: 0:00:00.026905\n",
      "Epoch 953/1500, Train Loss: 0.0079,       Test Loss: 0.0093, Duration: 0:00:00.027086\n",
      "Epoch 954/1500, Train Loss: 0.0080,       Test Loss: 0.0092, Duration: 0:00:00.026402\n",
      "Epoch 955/1500, Train Loss: 0.0069,       Test Loss: 0.0076, Duration: 0:00:00.026404\n",
      "Epoch 956/1500, Train Loss: 0.0063,       Test Loss: 0.0071, Duration: 0:00:00.026949\n",
      "Epoch 957/1500, Train Loss: 0.0064,       Test Loss: 0.0072, Duration: 0:00:00.025884\n",
      "Epoch 958/1500, Train Loss: 0.0065,       Test Loss: 0.0070, Duration: 0:00:00.026188\n",
      "Epoch 959/1500, Train Loss: 0.0064,       Test Loss: 0.0064, Duration: 0:00:00.025638\n",
      "Epoch 960/1500, Train Loss: 0.0064,       Test Loss: 0.0079, Duration: 0:00:00.026339\n",
      "Epoch 961/1500, Train Loss: 0.0073,       Test Loss: 0.0083, Duration: 0:00:00.027479\n",
      "Epoch 962/1500, Train Loss: 0.0074,       Test Loss: 0.0075, Duration: 0:00:00.026386\n",
      "Epoch 963/1500, Train Loss: 0.0067,       Test Loss: 0.0073, Duration: 0:00:00.025944\n",
      "Epoch 964/1500, Train Loss: 0.0066,       Test Loss: 0.0067, Duration: 0:00:00.026226\n",
      "Epoch 965/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.025904\n",
      "Epoch 966/1500, Train Loss: 0.0058,       Test Loss: 0.0060, Duration: 0:00:00.025784\n",
      "Epoch 967/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.025847\n",
      "Epoch 968/1500, Train Loss: 0.0054,       Test Loss: 0.0058, Duration: 0:00:00.026575\n",
      "Epoch 969/1500, Train Loss: 0.0058,       Test Loss: 0.0061, Duration: 0:00:00.027544\n",
      "Epoch 970/1500, Train Loss: 0.0059,       Test Loss: 0.0063, Duration: 0:00:00.026597\n",
      "Epoch 971/1500, Train Loss: 0.0059,       Test Loss: 0.0063, Duration: 0:00:00.026324\n",
      "Epoch 972/1500, Train Loss: 0.0060,       Test Loss: 0.0075, Duration: 0:00:00.025964\n",
      "Epoch 973/1500, Train Loss: 0.0067,       Test Loss: 0.0064, Duration: 0:00:00.026108\n",
      "Epoch 974/1500, Train Loss: 0.0062,       Test Loss: 0.0070, Duration: 0:00:00.025574\n",
      "Epoch 975/1500, Train Loss: 0.0066,       Test Loss: 0.0076, Duration: 0:00:00.026945\n",
      "Epoch 976/1500, Train Loss: 0.0072,       Test Loss: 0.0086, Duration: 0:00:00.026404\n",
      "Epoch 977/1500, Train Loss: 0.0073,       Test Loss: 0.0080, Duration: 0:00:00.027833\n",
      "Epoch 978/1500, Train Loss: 0.0073,       Test Loss: 0.0091, Duration: 0:00:00.026402\n",
      "Epoch 979/1500, Train Loss: 0.0079,       Test Loss: 0.0081, Duration: 0:00:00.026268\n",
      "Epoch 980/1500, Train Loss: 0.0066,       Test Loss: 0.0073, Duration: 0:00:00.025784\n",
      "Epoch 981/1500, Train Loss: 0.0062,       Test Loss: 0.0064, Duration: 0:00:00.026302\n",
      "Epoch 982/1500, Train Loss: 0.0061,       Test Loss: 0.0064, Duration: 0:00:00.026021\n",
      "Epoch 983/1500, Train Loss: 0.0065,       Test Loss: 0.0068, Duration: 0:00:00.025704\n",
      "Epoch 984/1500, Train Loss: 0.0066,       Test Loss: 0.0075, Duration: 0:00:00.026609\n",
      "Epoch 985/1500, Train Loss: 0.0072,       Test Loss: 0.0073, Duration: 0:00:00.027318\n",
      "Epoch 986/1500, Train Loss: 0.0064,       Test Loss: 0.0068, Duration: 0:00:00.026291\n",
      "Epoch 987/1500, Train Loss: 0.0062,       Test Loss: 0.0069, Duration: 0:00:00.025979\n",
      "Epoch 988/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.026211\n",
      "Epoch 989/1500, Train Loss: 0.0060,       Test Loss: 0.0058, Duration: 0:00:00.025432\n",
      "Epoch 990/1500, Train Loss: 0.0056,       Test Loss: 0.0055, Duration: 0:00:00.026066\n",
      "Epoch 991/1500, Train Loss: 0.0058,       Test Loss: 0.0059, Duration: 0:00:00.025495\n",
      "Epoch 992/1500, Train Loss: 0.0058,       Test Loss: 0.0069, Duration: 0:00:00.026786\n",
      "Epoch 993/1500, Train Loss: 0.0063,       Test Loss: 0.0068, Duration: 0:00:00.027399\n",
      "Epoch 994/1500, Train Loss: 0.0063,       Test Loss: 0.0064, Duration: 0:00:00.027411\n",
      "Epoch 995/1500, Train Loss: 0.0063,       Test Loss: 0.0061, Duration: 0:00:00.025967\n",
      "Epoch 996/1500, Train Loss: 0.0054,       Test Loss: 0.0062, Duration: 0:00:00.026134\n",
      "Epoch 997/1500, Train Loss: 0.0059,       Test Loss: 0.0066, Duration: 0:00:00.026050\n",
      "Epoch 998/1500, Train Loss: 0.0060,       Test Loss: 0.0063, Duration: 0:00:00.026123\n",
      "Epoch 999/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.025978\n",
      "Epoch 1000/1500, Train Loss: 0.0057,       Test Loss: 0.0055, Duration: 0:00:00.026749\n",
      "Epoch 1001/1500, Train Loss: 0.0053,       Test Loss: 0.0054, Duration: 0:00:00.027352\n",
      "Epoch 1002/1500, Train Loss: 0.0056,       Test Loss: 0.0062, Duration: 0:00:00.026380\n",
      "Epoch 1003/1500, Train Loss: 0.0058,       Test Loss: 0.0085, Duration: 0:00:00.026449\n",
      "Epoch 1004/1500, Train Loss: 0.0071,       Test Loss: 0.0074, Duration: 0:00:00.025943\n",
      "Epoch 1005/1500, Train Loss: 0.0066,       Test Loss: 0.0078, Duration: 0:00:00.025916\n",
      "Epoch 1006/1500, Train Loss: 0.0063,       Test Loss: 0.0058, Duration: 0:00:00.025947\n",
      "Epoch 1007/1500, Train Loss: 0.0057,       Test Loss: 0.0068, Duration: 0:00:00.025924\n",
      "Epoch 1008/1500, Train Loss: 0.0064,       Test Loss: 0.0072, Duration: 0:00:00.026854\n",
      "Epoch 1009/1500, Train Loss: 0.0065,       Test Loss: 0.0065, Duration: 0:00:00.027661\n",
      "Epoch 1010/1500, Train Loss: 0.0060,       Test Loss: 0.0059, Duration: 0:00:00.026364\n",
      "Epoch 1011/1500, Train Loss: 0.0059,       Test Loss: 0.0061, Duration: 0:00:00.026347\n",
      "Epoch 1012/1500, Train Loss: 0.0057,       Test Loss: 0.0064, Duration: 0:00:00.026079\n",
      "Epoch 1013/1500, Train Loss: 0.0059,       Test Loss: 0.0071, Duration: 0:00:00.026726\n",
      "Epoch 1014/1500, Train Loss: 0.0071,       Test Loss: 0.0100, Duration: 0:00:00.026280\n",
      "Epoch 1015/1500, Train Loss: 0.0081,       Test Loss: 0.0091, Duration: 0:00:00.026052\n",
      "Epoch 1016/1500, Train Loss: 0.0069,       Test Loss: 0.0078, Duration: 0:00:00.026673\n",
      "Epoch 1017/1500, Train Loss: 0.0065,       Test Loss: 0.0080, Duration: 0:00:00.027054\n",
      "Epoch 1018/1500, Train Loss: 0.0065,       Test Loss: 0.0078, Duration: 0:00:00.025780\n",
      "Epoch 1019/1500, Train Loss: 0.0069,       Test Loss: 0.0063, Duration: 0:00:00.025942\n",
      "Epoch 1020/1500, Train Loss: 0.0062,       Test Loss: 0.0075, Duration: 0:00:00.026314\n",
      "Epoch 1021/1500, Train Loss: 0.0062,       Test Loss: 0.0064, Duration: 0:00:00.026055\n",
      "Epoch 1022/1500, Train Loss: 0.0058,       Test Loss: 0.0057, Duration: 0:00:00.026015\n",
      "Epoch 1023/1500, Train Loss: 0.0053,       Test Loss: 0.0060, Duration: 0:00:00.026020\n",
      "Epoch 1024/1500, Train Loss: 0.0057,       Test Loss: 0.0059, Duration: 0:00:00.026702\n",
      "Epoch 1025/1500, Train Loss: 0.0053,       Test Loss: 0.0051, Duration: 0:00:00.027259\n",
      "Epoch 1026/1500, Train Loss: 0.0051,       Test Loss: 0.0056, Duration: 0:00:00.026378\n",
      "Epoch 1027/1500, Train Loss: 0.0057,       Test Loss: 0.0059, Duration: 0:00:00.026593\n",
      "Epoch 1028/1500, Train Loss: 0.0058,       Test Loss: 0.0063, Duration: 0:00:00.025993\n",
      "Epoch 1029/1500, Train Loss: 0.0059,       Test Loss: 0.0067, Duration: 0:00:00.025869\n",
      "Epoch 1030/1500, Train Loss: 0.0060,       Test Loss: 0.0052, Duration: 0:00:00.026522\n",
      "Epoch 1031/1500, Train Loss: 0.0053,       Test Loss: 0.0046, Duration: 0:00:00.026016\n",
      "Epoch 1032/1500, Train Loss: 0.0051,       Test Loss: 0.0045, Duration: 0:00:00.027386\n",
      "Epoch 1033/1500, Train Loss: 0.0045,       Test Loss: 0.0036, Duration: 0:00:00.027681\n",
      "Epoch 1034/1500, Train Loss: 0.0044,       Test Loss: 0.0040, Duration: 0:00:00.026024\n",
      "Epoch 1035/1500, Train Loss: 0.0044,       Test Loss: 0.0042, Duration: 0:00:00.025798\n",
      "Epoch 1036/1500, Train Loss: 0.0045,       Test Loss: 0.0042, Duration: 0:00:00.025703\n",
      "Epoch 1037/1500, Train Loss: 0.0046,       Test Loss: 0.0042, Duration: 0:00:00.026095\n",
      "Epoch 1038/1500, Train Loss: 0.0049,       Test Loss: 0.0039, Duration: 0:00:00.025985\n",
      "Epoch 1039/1500, Train Loss: 0.0046,       Test Loss: 0.0040, Duration: 0:00:00.026130\n",
      "Epoch 1040/1500, Train Loss: 0.0045,       Test Loss: 0.0040, Duration: 0:00:00.026815\n",
      "Epoch 1041/1500, Train Loss: 0.0047,       Test Loss: 0.0041, Duration: 0:00:00.028451\n",
      "Epoch 1042/1500, Train Loss: 0.0049,       Test Loss: 0.0049, Duration: 0:00:00.029955\n",
      "Epoch 1043/1500, Train Loss: 0.0051,       Test Loss: 0.0047, Duration: 0:00:00.029841\n",
      "Epoch 1044/1500, Train Loss: 0.0051,       Test Loss: 0.0053, Duration: 0:00:00.030153\n",
      "Epoch 1045/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.029730\n",
      "Epoch 1046/1500, Train Loss: 0.0048,       Test Loss: 0.0056, Duration: 0:00:00.029767\n",
      "Epoch 1047/1500, Train Loss: 0.0057,       Test Loss: 0.0077, Duration: 0:00:00.036649\n",
      "Epoch 1048/1500, Train Loss: 0.0056,       Test Loss: 0.0046, Duration: 0:00:00.030741\n",
      "Epoch 1049/1500, Train Loss: 0.0046,       Test Loss: 0.0044, Duration: 0:00:00.030626\n",
      "Epoch 1050/1500, Train Loss: 0.0045,       Test Loss: 0.0040, Duration: 0:00:00.030253\n",
      "Epoch 1051/1500, Train Loss: 0.0046,       Test Loss: 0.0049, Duration: 0:00:00.030165\n",
      "Epoch 1052/1500, Train Loss: 0.0051,       Test Loss: 0.0056, Duration: 0:00:00.027450\n",
      "Epoch 1053/1500, Train Loss: 0.0052,       Test Loss: 0.0052, Duration: 0:00:00.026229\n",
      "Epoch 1054/1500, Train Loss: 0.0051,       Test Loss: 0.0047, Duration: 0:00:00.026497\n",
      "Epoch 1055/1500, Train Loss: 0.0050,       Test Loss: 0.0059, Duration: 0:00:00.026785\n",
      "Epoch 1056/1500, Train Loss: 0.0052,       Test Loss: 0.0056, Duration: 0:00:00.027418\n",
      "Epoch 1057/1500, Train Loss: 0.0049,       Test Loss: 0.0047, Duration: 0:00:00.026126\n",
      "Epoch 1058/1500, Train Loss: 0.0050,       Test Loss: 0.0057, Duration: 0:00:00.025884\n",
      "Epoch 1059/1500, Train Loss: 0.0056,       Test Loss: 0.0059, Duration: 0:00:00.025622\n",
      "Epoch 1060/1500, Train Loss: 0.0053,       Test Loss: 0.0056, Duration: 0:00:00.025666\n",
      "Epoch 1061/1500, Train Loss: 0.0059,       Test Loss: 0.0092, Duration: 0:00:00.025568\n",
      "Epoch 1062/1500, Train Loss: 0.0071,       Test Loss: 0.0087, Duration: 0:00:00.026580\n",
      "Epoch 1063/1500, Train Loss: 0.0071,       Test Loss: 0.0084, Duration: 0:00:00.026898\n",
      "Epoch 1064/1500, Train Loss: 0.0076,       Test Loss: 0.0084, Duration: 0:00:00.026534\n",
      "Epoch 1065/1500, Train Loss: 0.0069,       Test Loss: 0.0069, Duration: 0:00:00.025930\n",
      "Epoch 1066/1500, Train Loss: 0.0061,       Test Loss: 0.0072, Duration: 0:00:00.026006\n",
      "Epoch 1067/1500, Train Loss: 0.0060,       Test Loss: 0.0066, Duration: 0:00:00.025504\n",
      "Epoch 1068/1500, Train Loss: 0.0060,       Test Loss: 0.0065, Duration: 0:00:00.026552\n",
      "Epoch 1069/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.025770\n",
      "Epoch 1070/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026594\n",
      "Epoch 1071/1500, Train Loss: 0.0052,       Test Loss: 0.0059, Duration: 0:00:00.027507\n",
      "Epoch 1072/1500, Train Loss: 0.0065,       Test Loss: 0.0078, Duration: 0:00:00.026236\n",
      "Epoch 1073/1500, Train Loss: 0.0067,       Test Loss: 0.0074, Duration: 0:00:00.026052\n",
      "Epoch 1074/1500, Train Loss: 0.0066,       Test Loss: 0.0081, Duration: 0:00:00.026324\n",
      "Epoch 1075/1500, Train Loss: 0.0068,       Test Loss: 0.0089, Duration: 0:00:00.025997\n",
      "Epoch 1076/1500, Train Loss: 0.0079,       Test Loss: 0.0111, Duration: 0:00:00.025869\n",
      "Epoch 1077/1500, Train Loss: 0.0091,       Test Loss: 0.0094, Duration: 0:00:00.026225\n",
      "Epoch 1078/1500, Train Loss: 0.0081,       Test Loss: 0.0084, Duration: 0:00:00.026727\n",
      "Epoch 1079/1500, Train Loss: 0.0073,       Test Loss: 0.0069, Duration: 0:00:00.027353\n",
      "Epoch 1080/1500, Train Loss: 0.0062,       Test Loss: 0.0068, Duration: 0:00:00.026366\n",
      "Epoch 1081/1500, Train Loss: 0.0070,       Test Loss: 0.0079, Duration: 0:00:00.026103\n",
      "Epoch 1082/1500, Train Loss: 0.0075,       Test Loss: 0.0100, Duration: 0:00:00.026128\n",
      "Epoch 1083/1500, Train Loss: 0.0080,       Test Loss: 0.0080, Duration: 0:00:00.026328\n",
      "Epoch 1084/1500, Train Loss: 0.0062,       Test Loss: 0.0070, Duration: 0:00:00.025942\n",
      "Epoch 1085/1500, Train Loss: 0.0068,       Test Loss: 0.0081, Duration: 0:00:00.026090\n",
      "Epoch 1086/1500, Train Loss: 0.0069,       Test Loss: 0.0087, Duration: 0:00:00.026646\n",
      "Epoch 1087/1500, Train Loss: 0.0072,       Test Loss: 0.0082, Duration: 0:00:00.027733\n",
      "Epoch 1088/1500, Train Loss: 0.0068,       Test Loss: 0.0073, Duration: 0:00:00.026897\n",
      "Epoch 1089/1500, Train Loss: 0.0065,       Test Loss: 0.0076, Duration: 0:00:00.026178\n",
      "Epoch 1090/1500, Train Loss: 0.0069,       Test Loss: 0.0075, Duration: 0:00:00.025826\n",
      "Epoch 1091/1500, Train Loss: 0.0065,       Test Loss: 0.0087, Duration: 0:00:00.025796\n",
      "Epoch 1092/1500, Train Loss: 0.0068,       Test Loss: 0.0067, Duration: 0:00:00.025922\n",
      "Epoch 1093/1500, Train Loss: 0.0066,       Test Loss: 0.0074, Duration: 0:00:00.026325\n",
      "Epoch 1094/1500, Train Loss: 0.0064,       Test Loss: 0.0060, Duration: 0:00:00.026541\n",
      "Epoch 1095/1500, Train Loss: 0.0060,       Test Loss: 0.0046, Duration: 0:00:00.027526\n",
      "Epoch 1096/1500, Train Loss: 0.0048,       Test Loss: 0.0038, Duration: 0:00:00.026395\n",
      "Epoch 1097/1500, Train Loss: 0.0046,       Test Loss: 0.0036, Duration: 0:00:00.026312\n",
      "Epoch 1098/1500, Train Loss: 0.0042,       Test Loss: 0.0034, Duration: 0:00:00.026067\n",
      "Epoch 1099/1500, Train Loss: 0.0043,       Test Loss: 0.0036, Duration: 0:00:00.025975\n",
      "Epoch 1100/1500, Train Loss: 0.0046,       Test Loss: 0.0043, Duration: 0:00:00.026218\n",
      "Epoch 1101/1500, Train Loss: 0.0045,       Test Loss: 0.0037, Duration: 0:00:00.025929\n",
      "Epoch 1102/1500, Train Loss: 0.0042,       Test Loss: 0.0039, Duration: 0:00:00.026723\n",
      "Epoch 1103/1500, Train Loss: 0.0045,       Test Loss: 0.0039, Duration: 0:00:00.027603\n",
      "Epoch 1104/1500, Train Loss: 0.0043,       Test Loss: 0.0037, Duration: 0:00:00.026550\n",
      "Epoch 1105/1500, Train Loss: 0.0044,       Test Loss: 0.0047, Duration: 0:00:00.025985\n",
      "Epoch 1106/1500, Train Loss: 0.0049,       Test Loss: 0.0043, Duration: 0:00:00.027135\n",
      "Epoch 1107/1500, Train Loss: 0.0046,       Test Loss: 0.0045, Duration: 0:00:00.026222\n",
      "Epoch 1108/1500, Train Loss: 0.0048,       Test Loss: 0.0044, Duration: 0:00:00.026048\n",
      "Epoch 1109/1500, Train Loss: 0.0047,       Test Loss: 0.0041, Duration: 0:00:00.025946\n",
      "Epoch 1110/1500, Train Loss: 0.0048,       Test Loss: 0.0049, Duration: 0:00:00.026760\n",
      "Epoch 1111/1500, Train Loss: 0.0052,       Test Loss: 0.0052, Duration: 0:00:00.026982\n",
      "Epoch 1112/1500, Train Loss: 0.0054,       Test Loss: 0.0047, Duration: 0:00:00.026418\n",
      "Epoch 1113/1500, Train Loss: 0.0045,       Test Loss: 0.0042, Duration: 0:00:00.026028\n",
      "Epoch 1114/1500, Train Loss: 0.0049,       Test Loss: 0.0055, Duration: 0:00:00.025648\n",
      "Epoch 1115/1500, Train Loss: 0.0052,       Test Loss: 0.0058, Duration: 0:00:00.025899\n",
      "Epoch 1116/1500, Train Loss: 0.0056,       Test Loss: 0.0061, Duration: 0:00:00.025910\n",
      "Epoch 1117/1500, Train Loss: 0.0060,       Test Loss: 0.0074, Duration: 0:00:00.026214\n",
      "Epoch 1118/1500, Train Loss: 0.0064,       Test Loss: 0.0073, Duration: 0:00:00.026490\n",
      "Epoch 1119/1500, Train Loss: 0.0063,       Test Loss: 0.0072, Duration: 0:00:00.027294\n",
      "Epoch 1120/1500, Train Loss: 0.0062,       Test Loss: 0.0085, Duration: 0:00:00.026618\n",
      "Epoch 1121/1500, Train Loss: 0.0071,       Test Loss: 0.0085, Duration: 0:00:00.025950\n",
      "Epoch 1122/1500, Train Loss: 0.0074,       Test Loss: 0.0116, Duration: 0:00:00.025698\n",
      "Epoch 1123/1500, Train Loss: 0.0087,       Test Loss: 0.0097, Duration: 0:00:00.025834\n",
      "Epoch 1124/1500, Train Loss: 0.0075,       Test Loss: 0.0124, Duration: 0:00:00.025650\n",
      "Epoch 1125/1500, Train Loss: 0.0091,       Test Loss: 0.0076, Duration: 0:00:00.026977\n",
      "Epoch 1126/1500, Train Loss: 0.0068,       Test Loss: 0.0082, Duration: 0:00:00.026788\n",
      "Epoch 1127/1500, Train Loss: 0.0070,       Test Loss: 0.0074, Duration: 0:00:00.027456\n",
      "Epoch 1128/1500, Train Loss: 0.0066,       Test Loss: 0.0077, Duration: 0:00:00.026599\n",
      "Epoch 1129/1500, Train Loss: 0.0067,       Test Loss: 0.0070, Duration: 0:00:00.031453\n",
      "Epoch 1130/1500, Train Loss: 0.0065,       Test Loss: 0.0077, Duration: 0:00:00.026829\n",
      "Epoch 1131/1500, Train Loss: 0.0068,       Test Loss: 0.0064, Duration: 0:00:00.025818\n",
      "Epoch 1132/1500, Train Loss: 0.0053,       Test Loss: 0.0045, Duration: 0:00:00.026170\n",
      "Epoch 1133/1500, Train Loss: 0.0050,       Test Loss: 0.0046, Duration: 0:00:00.025876\n",
      "Epoch 1134/1500, Train Loss: 0.0054,       Test Loss: 0.0061, Duration: 0:00:00.026993\n",
      "Epoch 1135/1500, Train Loss: 0.0061,       Test Loss: 0.0068, Duration: 0:00:00.027691\n",
      "Epoch 1136/1500, Train Loss: 0.0059,       Test Loss: 0.0061, Duration: 0:00:00.026375\n",
      "Epoch 1137/1500, Train Loss: 0.0053,       Test Loss: 0.0055, Duration: 0:00:00.025873\n",
      "Epoch 1138/1500, Train Loss: 0.0052,       Test Loss: 0.0047, Duration: 0:00:00.026052\n",
      "Epoch 1139/1500, Train Loss: 0.0050,       Test Loss: 0.0044, Duration: 0:00:00.025821\n",
      "Epoch 1140/1500, Train Loss: 0.0047,       Test Loss: 0.0046, Duration: 0:00:00.026169\n",
      "Epoch 1141/1500, Train Loss: 0.0047,       Test Loss: 0.0045, Duration: 0:00:00.026140\n",
      "Epoch 1142/1500, Train Loss: 0.0045,       Test Loss: 0.0041, Duration: 0:00:00.026825\n",
      "Epoch 1143/1500, Train Loss: 0.0047,       Test Loss: 0.0051, Duration: 0:00:00.027302\n",
      "Epoch 1144/1500, Train Loss: 0.0051,       Test Loss: 0.0057, Duration: 0:00:00.026850\n",
      "Epoch 1145/1500, Train Loss: 0.0055,       Test Loss: 0.0063, Duration: 0:00:00.026320\n",
      "Epoch 1146/1500, Train Loss: 0.0058,       Test Loss: 0.0076, Duration: 0:00:00.025857\n",
      "Epoch 1147/1500, Train Loss: 0.0059,       Test Loss: 0.0060, Duration: 0:00:00.026228\n",
      "Epoch 1148/1500, Train Loss: 0.0050,       Test Loss: 0.0054, Duration: 0:00:00.025960\n",
      "Epoch 1149/1500, Train Loss: 0.0051,       Test Loss: 0.0052, Duration: 0:00:00.026112\n",
      "Epoch 1150/1500, Train Loss: 0.0051,       Test Loss: 0.0059, Duration: 0:00:00.026585\n",
      "Epoch 1151/1500, Train Loss: 0.0058,       Test Loss: 0.0069, Duration: 0:00:00.027495\n",
      "Epoch 1152/1500, Train Loss: 0.0061,       Test Loss: 0.0059, Duration: 0:00:00.026213\n",
      "Epoch 1153/1500, Train Loss: 0.0054,       Test Loss: 0.0060, Duration: 0:00:00.026331\n",
      "Epoch 1154/1500, Train Loss: 0.0056,       Test Loss: 0.0069, Duration: 0:00:00.025688\n",
      "Epoch 1155/1500, Train Loss: 0.0067,       Test Loss: 0.0079, Duration: 0:00:00.026101\n",
      "Epoch 1156/1500, Train Loss: 0.0071,       Test Loss: 0.0097, Duration: 0:00:00.025993\n",
      "Epoch 1157/1500, Train Loss: 0.0084,       Test Loss: 0.0090, Duration: 0:00:00.026017\n",
      "Epoch 1158/1500, Train Loss: 0.0071,       Test Loss: 0.0062, Duration: 0:00:00.027072\n",
      "Epoch 1159/1500, Train Loss: 0.0055,       Test Loss: 0.0048, Duration: 0:00:00.027412\n",
      "Epoch 1160/1500, Train Loss: 0.0050,       Test Loss: 0.0049, Duration: 0:00:00.026258\n",
      "Epoch 1161/1500, Train Loss: 0.0049,       Test Loss: 0.0051, Duration: 0:00:00.026143\n",
      "Epoch 1162/1500, Train Loss: 0.0052,       Test Loss: 0.0055, Duration: 0:00:00.026339\n",
      "Epoch 1163/1500, Train Loss: 0.0055,       Test Loss: 0.0057, Duration: 0:00:00.027065\n",
      "Epoch 1164/1500, Train Loss: 0.0057,       Test Loss: 0.0046, Duration: 0:00:00.026266\n",
      "Epoch 1165/1500, Train Loss: 0.0053,       Test Loss: 0.0052, Duration: 0:00:00.025592\n",
      "Epoch 1166/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.026660\n",
      "Epoch 1167/1500, Train Loss: 0.0053,       Test Loss: 0.0045, Duration: 0:00:00.027252\n",
      "Epoch 1168/1500, Train Loss: 0.0045,       Test Loss: 0.0040, Duration: 0:00:00.026552\n",
      "Epoch 1169/1500, Train Loss: 0.0045,       Test Loss: 0.0045, Duration: 0:00:00.025886\n",
      "Epoch 1170/1500, Train Loss: 0.0048,       Test Loss: 0.0055, Duration: 0:00:00.026073\n",
      "Epoch 1171/1500, Train Loss: 0.0055,       Test Loss: 0.0057, Duration: 0:00:00.025695\n",
      "Epoch 1172/1500, Train Loss: 0.0053,       Test Loss: 0.0061, Duration: 0:00:00.026349\n",
      "Epoch 1173/1500, Train Loss: 0.0055,       Test Loss: 0.0048, Duration: 0:00:00.025852\n",
      "Epoch 1174/1500, Train Loss: 0.0049,       Test Loss: 0.0046, Duration: 0:00:00.026768\n",
      "Epoch 1175/1500, Train Loss: 0.0049,       Test Loss: 0.0047, Duration: 0:00:00.026894\n",
      "Epoch 1176/1500, Train Loss: 0.0052,       Test Loss: 0.0049, Duration: 0:00:00.026417\n",
      "Epoch 1177/1500, Train Loss: 0.0052,       Test Loss: 0.0060, Duration: 0:00:00.026267\n",
      "Epoch 1178/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026038\n",
      "Epoch 1179/1500, Train Loss: 0.0053,       Test Loss: 0.0047, Duration: 0:00:00.025992\n",
      "Epoch 1180/1500, Train Loss: 0.0046,       Test Loss: 0.0052, Duration: 0:00:00.025971\n",
      "Epoch 1181/1500, Train Loss: 0.0051,       Test Loss: 0.0062, Duration: 0:00:00.026484\n",
      "Epoch 1182/1500, Train Loss: 0.0058,       Test Loss: 0.0075, Duration: 0:00:00.027463\n",
      "Epoch 1183/1500, Train Loss: 0.0069,       Test Loss: 0.0074, Duration: 0:00:00.027109\n",
      "Epoch 1184/1500, Train Loss: 0.0066,       Test Loss: 0.0072, Duration: 0:00:00.025736\n",
      "Epoch 1185/1500, Train Loss: 0.0064,       Test Loss: 0.0074, Duration: 0:00:00.025710\n",
      "Epoch 1186/1500, Train Loss: 0.0070,       Test Loss: 0.0084, Duration: 0:00:00.025528\n",
      "Epoch 1187/1500, Train Loss: 0.0078,       Test Loss: 0.0062, Duration: 0:00:00.025777\n",
      "Epoch 1188/1500, Train Loss: 0.0060,       Test Loss: 0.0067, Duration: 0:00:00.025433\n",
      "Epoch 1189/1500, Train Loss: 0.0055,       Test Loss: 0.0057, Duration: 0:00:00.026119\n",
      "Epoch 1190/1500, Train Loss: 0.0054,       Test Loss: 0.0069, Duration: 0:00:00.026439\n",
      "Epoch 1191/1500, Train Loss: 0.0060,       Test Loss: 0.0064, Duration: 0:00:00.026954\n",
      "Epoch 1192/1500, Train Loss: 0.0059,       Test Loss: 0.0068, Duration: 0:00:00.026636\n",
      "Epoch 1193/1500, Train Loss: 0.0064,       Test Loss: 0.0064, Duration: 0:00:00.026147\n",
      "Epoch 1194/1500, Train Loss: 0.0056,       Test Loss: 0.0057, Duration: 0:00:00.026414\n",
      "Epoch 1195/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.026020\n",
      "Epoch 1196/1500, Train Loss: 0.0050,       Test Loss: 0.0042, Duration: 0:00:00.026228\n",
      "Epoch 1197/1500, Train Loss: 0.0048,       Test Loss: 0.0052, Duration: 0:00:00.025970\n",
      "Epoch 1198/1500, Train Loss: 0.0049,       Test Loss: 0.0050, Duration: 0:00:00.026356\n",
      "Epoch 1199/1500, Train Loss: 0.0047,       Test Loss: 0.0046, Duration: 0:00:00.027036\n",
      "Epoch 1200/1500, Train Loss: 0.0046,       Test Loss: 0.0050, Duration: 0:00:00.026427\n",
      "Epoch 1201/1500, Train Loss: 0.0047,       Test Loss: 0.0056, Duration: 0:00:00.027145\n",
      "Epoch 1202/1500, Train Loss: 0.0049,       Test Loss: 0.0056, Duration: 0:00:00.026328\n",
      "Epoch 1203/1500, Train Loss: 0.0053,       Test Loss: 0.0059, Duration: 0:00:00.026138\n",
      "Epoch 1204/1500, Train Loss: 0.0054,       Test Loss: 0.0065, Duration: 0:00:00.026376\n",
      "Epoch 1205/1500, Train Loss: 0.0056,       Test Loss: 0.0064, Duration: 0:00:00.026037\n",
      "Epoch 1206/1500, Train Loss: 0.0058,       Test Loss: 0.0081, Duration: 0:00:00.026929\n",
      "Epoch 1207/1500, Train Loss: 0.0061,       Test Loss: 0.0079, Duration: 0:00:00.027521\n",
      "Epoch 1208/1500, Train Loss: 0.0064,       Test Loss: 0.0073, Duration: 0:00:00.026321\n",
      "Epoch 1209/1500, Train Loss: 0.0056,       Test Loss: 0.0063, Duration: 0:00:00.025964\n",
      "Epoch 1210/1500, Train Loss: 0.0063,       Test Loss: 0.0086, Duration: 0:00:00.026063\n",
      "Epoch 1211/1500, Train Loss: 0.0068,       Test Loss: 0.0080, Duration: 0:00:00.026029\n",
      "Epoch 1212/1500, Train Loss: 0.0067,       Test Loss: 0.0073, Duration: 0:00:00.026057\n",
      "Epoch 1213/1500, Train Loss: 0.0067,       Test Loss: 0.0074, Duration: 0:00:00.026206\n",
      "Epoch 1214/1500, Train Loss: 0.0059,       Test Loss: 0.0068, Duration: 0:00:00.026574\n",
      "Epoch 1215/1500, Train Loss: 0.0053,       Test Loss: 0.0054, Duration: 0:00:00.027058\n",
      "Epoch 1216/1500, Train Loss: 0.0051,       Test Loss: 0.0053, Duration: 0:00:00.026288\n",
      "Epoch 1217/1500, Train Loss: 0.0052,       Test Loss: 0.0058, Duration: 0:00:00.026089\n",
      "Epoch 1218/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.025709\n",
      "Epoch 1219/1500, Train Loss: 0.0047,       Test Loss: 0.0048, Duration: 0:00:00.026115\n",
      "Epoch 1220/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.026783\n",
      "Epoch 1221/1500, Train Loss: 0.0045,       Test Loss: 0.0038, Duration: 0:00:00.025800\n",
      "Epoch 1222/1500, Train Loss: 0.0044,       Test Loss: 0.0044, Duration: 0:00:00.026164\n",
      "Epoch 1223/1500, Train Loss: 0.0046,       Test Loss: 0.0040, Duration: 0:00:00.027155\n",
      "Epoch 1224/1500, Train Loss: 0.0044,       Test Loss: 0.0045, Duration: 0:00:00.026065\n",
      "Epoch 1225/1500, Train Loss: 0.0047,       Test Loss: 0.0048, Duration: 0:00:00.026228\n",
      "Epoch 1226/1500, Train Loss: 0.0046,       Test Loss: 0.0053, Duration: 0:00:00.025880\n",
      "Epoch 1227/1500, Train Loss: 0.0053,       Test Loss: 0.0059, Duration: 0:00:00.026285\n",
      "Epoch 1228/1500, Train Loss: 0.0054,       Test Loss: 0.0052, Duration: 0:00:00.025940\n",
      "Epoch 1229/1500, Train Loss: 0.0048,       Test Loss: 0.0045, Duration: 0:00:00.025791\n",
      "Epoch 1230/1500, Train Loss: 0.0051,       Test Loss: 0.0063, Duration: 0:00:00.026398\n",
      "Epoch 1231/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.027272\n",
      "Epoch 1232/1500, Train Loss: 0.0055,       Test Loss: 0.0062, Duration: 0:00:00.026296\n",
      "Epoch 1233/1500, Train Loss: 0.0055,       Test Loss: 0.0061, Duration: 0:00:00.025871\n",
      "Epoch 1234/1500, Train Loss: 0.0056,       Test Loss: 0.0061, Duration: 0:00:00.025998\n",
      "Epoch 1235/1500, Train Loss: 0.0056,       Test Loss: 0.0060, Duration: 0:00:00.026011\n",
      "Epoch 1236/1500, Train Loss: 0.0059,       Test Loss: 0.0071, Duration: 0:00:00.026071\n",
      "Epoch 1237/1500, Train Loss: 0.0059,       Test Loss: 0.0062, Duration: 0:00:00.025599\n",
      "Epoch 1238/1500, Train Loss: 0.0058,       Test Loss: 0.0065, Duration: 0:00:00.026515\n",
      "Epoch 1239/1500, Train Loss: 0.0054,       Test Loss: 0.0050, Duration: 0:00:00.027866\n",
      "Epoch 1240/1500, Train Loss: 0.0050,       Test Loss: 0.0055, Duration: 0:00:00.026280\n",
      "Epoch 1241/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026047\n",
      "Epoch 1242/1500, Train Loss: 0.0055,       Test Loss: 0.0062, Duration: 0:00:00.026090\n",
      "Epoch 1243/1500, Train Loss: 0.0057,       Test Loss: 0.0056, Duration: 0:00:00.025473\n",
      "Epoch 1244/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.025585\n",
      "Epoch 1245/1500, Train Loss: 0.0053,       Test Loss: 0.0055, Duration: 0:00:00.025581\n",
      "Epoch 1246/1500, Train Loss: 0.0053,       Test Loss: 0.0058, Duration: 0:00:00.026715\n",
      "Epoch 1247/1500, Train Loss: 0.0052,       Test Loss: 0.0056, Duration: 0:00:00.027064\n",
      "Epoch 1248/1500, Train Loss: 0.0058,       Test Loss: 0.0071, Duration: 0:00:00.026101\n",
      "Epoch 1249/1500, Train Loss: 0.0061,       Test Loss: 0.0061, Duration: 0:00:00.026607\n",
      "Epoch 1250/1500, Train Loss: 0.0058,       Test Loss: 0.0055, Duration: 0:00:00.025781\n",
      "Epoch 1251/1500, Train Loss: 0.0053,       Test Loss: 0.0052, Duration: 0:00:00.026064\n",
      "Epoch 1252/1500, Train Loss: 0.0053,       Test Loss: 0.0063, Duration: 0:00:00.026005\n",
      "Epoch 1253/1500, Train Loss: 0.0057,       Test Loss: 0.0058, Duration: 0:00:00.026076\n",
      "Epoch 1254/1500, Train Loss: 0.0051,       Test Loss: 0.0043, Duration: 0:00:00.026620\n",
      "Epoch 1255/1500, Train Loss: 0.0047,       Test Loss: 0.0045, Duration: 0:00:00.027552\n",
      "Epoch 1256/1500, Train Loss: 0.0052,       Test Loss: 0.0065, Duration: 0:00:00.026466\n",
      "Epoch 1257/1500, Train Loss: 0.0056,       Test Loss: 0.0053, Duration: 0:00:00.026335\n",
      "Epoch 1258/1500, Train Loss: 0.0059,       Test Loss: 0.0057, Duration: 0:00:00.026844\n",
      "Epoch 1259/1500, Train Loss: 0.0055,       Test Loss: 0.0047, Duration: 0:00:00.026208\n",
      "Epoch 1260/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.025921\n",
      "Epoch 1261/1500, Train Loss: 0.0045,       Test Loss: 0.0043, Duration: 0:00:00.026021\n",
      "Epoch 1262/1500, Train Loss: 0.0047,       Test Loss: 0.0048, Duration: 0:00:00.026565\n",
      "Epoch 1263/1500, Train Loss: 0.0046,       Test Loss: 0.0041, Duration: 0:00:00.027359\n",
      "Epoch 1264/1500, Train Loss: 0.0044,       Test Loss: 0.0042, Duration: 0:00:00.026148\n",
      "Epoch 1265/1500, Train Loss: 0.0042,       Test Loss: 0.0042, Duration: 0:00:00.026233\n",
      "Epoch 1266/1500, Train Loss: 0.0049,       Test Loss: 0.0049, Duration: 0:00:00.025474\n",
      "Epoch 1267/1500, Train Loss: 0.0053,       Test Loss: 0.0067, Duration: 0:00:00.025638\n",
      "Epoch 1268/1500, Train Loss: 0.0056,       Test Loss: 0.0060, Duration: 0:00:00.025385\n",
      "Epoch 1269/1500, Train Loss: 0.0052,       Test Loss: 0.0041, Duration: 0:00:00.025531\n",
      "Epoch 1270/1500, Train Loss: 0.0044,       Test Loss: 0.0043, Duration: 0:00:00.026304\n",
      "Epoch 1271/1500, Train Loss: 0.0044,       Test Loss: 0.0041, Duration: 0:00:00.027087\n",
      "Epoch 1272/1500, Train Loss: 0.0047,       Test Loss: 0.0053, Duration: 0:00:00.027071\n",
      "Epoch 1273/1500, Train Loss: 0.0051,       Test Loss: 0.0055, Duration: 0:00:00.026131\n",
      "Epoch 1274/1500, Train Loss: 0.0060,       Test Loss: 0.0068, Duration: 0:00:00.026279\n",
      "Epoch 1275/1500, Train Loss: 0.0057,       Test Loss: 0.0065, Duration: 0:00:00.026064\n",
      "Epoch 1276/1500, Train Loss: 0.0060,       Test Loss: 0.0074, Duration: 0:00:00.025909\n",
      "Epoch 1277/1500, Train Loss: 0.0056,       Test Loss: 0.0054, Duration: 0:00:00.026605\n",
      "Epoch 1278/1500, Train Loss: 0.0056,       Test Loss: 0.0058, Duration: 0:00:00.026847\n",
      "Epoch 1279/1500, Train Loss: 0.0054,       Test Loss: 0.0055, Duration: 0:00:00.026987\n",
      "Epoch 1280/1500, Train Loss: 0.0053,       Test Loss: 0.0061, Duration: 0:00:00.026045\n",
      "Epoch 1281/1500, Train Loss: 0.0056,       Test Loss: 0.0064, Duration: 0:00:00.026104\n",
      "Epoch 1282/1500, Train Loss: 0.0061,       Test Loss: 0.0080, Duration: 0:00:00.025639\n",
      "Epoch 1283/1500, Train Loss: 0.0059,       Test Loss: 0.0044, Duration: 0:00:00.025326\n",
      "Epoch 1284/1500, Train Loss: 0.0050,       Test Loss: 0.0045, Duration: 0:00:00.026137\n",
      "Epoch 1285/1500, Train Loss: 0.0047,       Test Loss: 0.0042, Duration: 0:00:00.025835\n",
      "Epoch 1286/1500, Train Loss: 0.0047,       Test Loss: 0.0045, Duration: 0:00:00.026773\n",
      "Epoch 1287/1500, Train Loss: 0.0049,       Test Loss: 0.0050, Duration: 0:00:00.027258\n",
      "Epoch 1288/1500, Train Loss: 0.0053,       Test Loss: 0.0051, Duration: 0:00:00.026547\n",
      "Epoch 1289/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.026457\n",
      "Epoch 1290/1500, Train Loss: 0.0055,       Test Loss: 0.0056, Duration: 0:00:00.026190\n",
      "Epoch 1291/1500, Train Loss: 0.0057,       Test Loss: 0.0055, Duration: 0:00:00.026310\n",
      "Epoch 1292/1500, Train Loss: 0.0058,       Test Loss: 0.0057, Duration: 0:00:00.025898\n",
      "Epoch 1293/1500, Train Loss: 0.0062,       Test Loss: 0.0071, Duration: 0:00:00.025918\n",
      "Epoch 1294/1500, Train Loss: 0.0060,       Test Loss: 0.0066, Duration: 0:00:00.026650\n",
      "Epoch 1295/1500, Train Loss: 0.0061,       Test Loss: 0.0068, Duration: 0:00:00.027580\n",
      "Epoch 1296/1500, Train Loss: 0.0061,       Test Loss: 0.0055, Duration: 0:00:00.027086\n",
      "Epoch 1297/1500, Train Loss: 0.0052,       Test Loss: 0.0053, Duration: 0:00:00.026421\n",
      "Epoch 1298/1500, Train Loss: 0.0051,       Test Loss: 0.0050, Duration: 0:00:00.025942\n",
      "Epoch 1299/1500, Train Loss: 0.0052,       Test Loss: 0.0051, Duration: 0:00:00.026294\n",
      "Epoch 1300/1500, Train Loss: 0.0053,       Test Loss: 0.0062, Duration: 0:00:00.025873\n",
      "Epoch 1301/1500, Train Loss: 0.0061,       Test Loss: 0.0079, Duration: 0:00:00.026086\n",
      "Epoch 1302/1500, Train Loss: 0.0074,       Test Loss: 0.0072, Duration: 0:00:00.026535\n",
      "Epoch 1303/1500, Train Loss: 0.0062,       Test Loss: 0.0058, Duration: 0:00:00.027600\n",
      "Epoch 1304/1500, Train Loss: 0.0058,       Test Loss: 0.0059, Duration: 0:00:00.026227\n",
      "Epoch 1305/1500, Train Loss: 0.0057,       Test Loss: 0.0066, Duration: 0:00:00.026287\n",
      "Epoch 1306/1500, Train Loss: 0.0066,       Test Loss: 0.0066, Duration: 0:00:00.026131\n",
      "Epoch 1307/1500, Train Loss: 0.0058,       Test Loss: 0.0065, Duration: 0:00:00.026199\n",
      "Epoch 1308/1500, Train Loss: 0.0063,       Test Loss: 0.0077, Duration: 0:00:00.026044\n",
      "Epoch 1309/1500, Train Loss: 0.0067,       Test Loss: 0.0076, Duration: 0:00:00.025901\n",
      "Epoch 1310/1500, Train Loss: 0.0066,       Test Loss: 0.0075, Duration: 0:00:00.026875\n",
      "Epoch 1311/1500, Train Loss: 0.0065,       Test Loss: 0.0068, Duration: 0:00:00.027341\n",
      "Epoch 1312/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.026605\n",
      "Epoch 1313/1500, Train Loss: 0.0061,       Test Loss: 0.0079, Duration: 0:00:00.026073\n",
      "Epoch 1314/1500, Train Loss: 0.0073,       Test Loss: 0.0090, Duration: 0:00:00.026125\n",
      "Epoch 1315/1500, Train Loss: 0.0073,       Test Loss: 0.0066, Duration: 0:00:00.026786\n",
      "Epoch 1316/1500, Train Loss: 0.0064,       Test Loss: 0.0062, Duration: 0:00:00.026215\n",
      "Epoch 1317/1500, Train Loss: 0.0057,       Test Loss: 0.0059, Duration: 0:00:00.025877\n",
      "Epoch 1318/1500, Train Loss: 0.0059,       Test Loss: 0.0065, Duration: 0:00:00.026860\n",
      "Epoch 1319/1500, Train Loss: 0.0053,       Test Loss: 0.0052, Duration: 0:00:00.026839\n",
      "Epoch 1320/1500, Train Loss: 0.0057,       Test Loss: 0.0065, Duration: 0:00:00.026310\n",
      "Epoch 1321/1500, Train Loss: 0.0060,       Test Loss: 0.0062, Duration: 0:00:00.025604\n",
      "Epoch 1322/1500, Train Loss: 0.0057,       Test Loss: 0.0063, Duration: 0:00:00.026403\n",
      "Epoch 1323/1500, Train Loss: 0.0068,       Test Loss: 0.0058, Duration: 0:00:00.026172\n",
      "Epoch 1324/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.025743\n",
      "Epoch 1325/1500, Train Loss: 0.0060,       Test Loss: 0.0061, Duration: 0:00:00.025618\n",
      "Epoch 1326/1500, Train Loss: 0.0061,       Test Loss: 0.0071, Duration: 0:00:00.026879\n",
      "Epoch 1327/1500, Train Loss: 0.0061,       Test Loss: 0.0064, Duration: 0:00:00.027400\n",
      "Epoch 1328/1500, Train Loss: 0.0060,       Test Loss: 0.0056, Duration: 0:00:00.026402\n",
      "Epoch 1329/1500, Train Loss: 0.0059,       Test Loss: 0.0055, Duration: 0:00:00.026400\n",
      "Epoch 1330/1500, Train Loss: 0.0059,       Test Loss: 0.0054, Duration: 0:00:00.026053\n",
      "Epoch 1331/1500, Train Loss: 0.0058,       Test Loss: 0.0074, Duration: 0:00:00.026006\n",
      "Epoch 1332/1500, Train Loss: 0.0062,       Test Loss: 0.0066, Duration: 0:00:00.025878\n",
      "Epoch 1333/1500, Train Loss: 0.0057,       Test Loss: 0.0045, Duration: 0:00:00.026129\n",
      "Epoch 1334/1500, Train Loss: 0.0052,       Test Loss: 0.0058, Duration: 0:00:00.027424\n",
      "Epoch 1335/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.027445\n",
      "Epoch 1336/1500, Train Loss: 0.0059,       Test Loss: 0.0058, Duration: 0:00:00.026503\n",
      "Epoch 1337/1500, Train Loss: 0.0066,       Test Loss: 0.0082, Duration: 0:00:00.026231\n",
      "Epoch 1338/1500, Train Loss: 0.0071,       Test Loss: 0.0068, Duration: 0:00:00.025940\n",
      "Epoch 1339/1500, Train Loss: 0.0063,       Test Loss: 0.0055, Duration: 0:00:00.025736\n",
      "Epoch 1340/1500, Train Loss: 0.0057,       Test Loss: 0.0054, Duration: 0:00:00.025701\n",
      "Epoch 1341/1500, Train Loss: 0.0058,       Test Loss: 0.0054, Duration: 0:00:00.025677\n",
      "Epoch 1342/1500, Train Loss: 0.0054,       Test Loss: 0.0057, Duration: 0:00:00.026506\n",
      "Epoch 1343/1500, Train Loss: 0.0053,       Test Loss: 0.0050, Duration: 0:00:00.027441\n",
      "Epoch 1344/1500, Train Loss: 0.0054,       Test Loss: 0.0056, Duration: 0:00:00.026769\n",
      "Epoch 1345/1500, Train Loss: 0.0058,       Test Loss: 0.0050, Duration: 0:00:00.026222\n",
      "Epoch 1346/1500, Train Loss: 0.0052,       Test Loss: 0.0051, Duration: 0:00:00.026463\n",
      "Epoch 1347/1500, Train Loss: 0.0055,       Test Loss: 0.0047, Duration: 0:00:00.025959\n",
      "Epoch 1348/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.026427\n",
      "Epoch 1349/1500, Train Loss: 0.0053,       Test Loss: 0.0056, Duration: 0:00:00.025976\n",
      "Epoch 1350/1500, Train Loss: 0.0057,       Test Loss: 0.0054, Duration: 0:00:00.026581\n",
      "Epoch 1351/1500, Train Loss: 0.0054,       Test Loss: 0.0047, Duration: 0:00:00.027114\n",
      "Epoch 1352/1500, Train Loss: 0.0049,       Test Loss: 0.0048, Duration: 0:00:00.026403\n",
      "Epoch 1353/1500, Train Loss: 0.0049,       Test Loss: 0.0046, Duration: 0:00:00.027159\n",
      "Epoch 1354/1500, Train Loss: 0.0049,       Test Loss: 0.0048, Duration: 0:00:00.026303\n",
      "Epoch 1355/1500, Train Loss: 0.0053,       Test Loss: 0.0049, Duration: 0:00:00.025643\n",
      "Epoch 1356/1500, Train Loss: 0.0053,       Test Loss: 0.0050, Duration: 0:00:00.026210\n",
      "Epoch 1357/1500, Train Loss: 0.0055,       Test Loss: 0.0071, Duration: 0:00:00.025786\n",
      "Epoch 1358/1500, Train Loss: 0.0074,       Test Loss: 0.0079, Duration: 0:00:00.026447\n",
      "Epoch 1359/1500, Train Loss: 0.0068,       Test Loss: 0.0063, Duration: 0:00:00.027430\n",
      "Epoch 1360/1500, Train Loss: 0.0057,       Test Loss: 0.0060, Duration: 0:00:00.025811\n",
      "Epoch 1361/1500, Train Loss: 0.0069,       Test Loss: 0.0062, Duration: 0:00:00.026015\n",
      "Epoch 1362/1500, Train Loss: 0.0063,       Test Loss: 0.0074, Duration: 0:00:00.025874\n",
      "Epoch 1363/1500, Train Loss: 0.0073,       Test Loss: 0.0103, Duration: 0:00:00.025631\n",
      "Epoch 1364/1500, Train Loss: 0.0083,       Test Loss: 0.0068, Duration: 0:00:00.025515\n",
      "Epoch 1365/1500, Train Loss: 0.0056,       Test Loss: 0.0056, Duration: 0:00:00.025581\n",
      "Epoch 1366/1500, Train Loss: 0.0058,       Test Loss: 0.0062, Duration: 0:00:00.026118\n",
      "Epoch 1367/1500, Train Loss: 0.0068,       Test Loss: 0.0068, Duration: 0:00:00.027326\n",
      "Epoch 1368/1500, Train Loss: 0.0069,       Test Loss: 0.0066, Duration: 0:00:00.026741\n",
      "Epoch 1369/1500, Train Loss: 0.0061,       Test Loss: 0.0051, Duration: 0:00:00.026386\n",
      "Epoch 1370/1500, Train Loss: 0.0053,       Test Loss: 0.0054, Duration: 0:00:00.025859\n",
      "Epoch 1371/1500, Train Loss: 0.0056,       Test Loss: 0.0060, Duration: 0:00:00.026354\n",
      "Epoch 1372/1500, Train Loss: 0.0062,       Test Loss: 0.0072, Duration: 0:00:00.026790\n",
      "Epoch 1373/1500, Train Loss: 0.0064,       Test Loss: 0.0063, Duration: 0:00:00.025729\n",
      "Epoch 1374/1500, Train Loss: 0.0055,       Test Loss: 0.0048, Duration: 0:00:00.025991\n",
      "Epoch 1375/1500, Train Loss: 0.0055,       Test Loss: 0.0062, Duration: 0:00:00.027579\n",
      "Epoch 1376/1500, Train Loss: 0.0062,       Test Loss: 0.0066, Duration: 0:00:00.026277\n",
      "Epoch 1377/1500, Train Loss: 0.0063,       Test Loss: 0.0070, Duration: 0:00:00.026126\n",
      "Epoch 1378/1500, Train Loss: 0.0067,       Test Loss: 0.0086, Duration: 0:00:00.026120\n",
      "Epoch 1379/1500, Train Loss: 0.0084,       Test Loss: 0.0102, Duration: 0:00:00.026097\n",
      "Epoch 1380/1500, Train Loss: 0.0087,       Test Loss: 0.0086, Duration: 0:00:00.026119\n",
      "Epoch 1381/1500, Train Loss: 0.0079,       Test Loss: 0.0106, Duration: 0:00:00.025986\n",
      "Epoch 1382/1500, Train Loss: 0.0123,       Test Loss: 0.0096, Duration: 0:00:00.026611\n",
      "Epoch 1383/1500, Train Loss: 0.0085,       Test Loss: 0.0062, Duration: 0:00:00.027507\n",
      "Epoch 1384/1500, Train Loss: 0.0053,       Test Loss: 0.0039, Duration: 0:00:00.026094\n",
      "Epoch 1385/1500, Train Loss: 0.0046,       Test Loss: 0.0040, Duration: 0:00:00.026198\n",
      "Epoch 1386/1500, Train Loss: 0.0047,       Test Loss: 0.0042, Duration: 0:00:00.026453\n",
      "Epoch 1387/1500, Train Loss: 0.0049,       Test Loss: 0.0048, Duration: 0:00:00.025721\n",
      "Epoch 1388/1500, Train Loss: 0.0057,       Test Loss: 0.0049, Duration: 0:00:00.026237\n",
      "Epoch 1389/1500, Train Loss: 0.0047,       Test Loss: 0.0043, Duration: 0:00:00.025739\n",
      "Epoch 1390/1500, Train Loss: 0.0047,       Test Loss: 0.0044, Duration: 0:00:00.026852\n",
      "Epoch 1391/1500, Train Loss: 0.0047,       Test Loss: 0.0048, Duration: 0:00:00.028294\n",
      "Epoch 1392/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.026200\n",
      "Epoch 1393/1500, Train Loss: 0.0045,       Test Loss: 0.0036, Duration: 0:00:00.025936\n",
      "Epoch 1394/1500, Train Loss: 0.0042,       Test Loss: 0.0037, Duration: 0:00:00.026060\n",
      "Epoch 1395/1500, Train Loss: 0.0048,       Test Loss: 0.0056, Duration: 0:00:00.025926\n",
      "Epoch 1396/1500, Train Loss: 0.0058,       Test Loss: 0.0056, Duration: 0:00:00.025947\n",
      "Epoch 1397/1500, Train Loss: 0.0054,       Test Loss: 0.0051, Duration: 0:00:00.025876\n",
      "Epoch 1398/1500, Train Loss: 0.0048,       Test Loss: 0.0042, Duration: 0:00:00.026716\n",
      "Epoch 1399/1500, Train Loss: 0.0047,       Test Loss: 0.0045, Duration: 0:00:00.027202\n",
      "Epoch 1400/1500, Train Loss: 0.0049,       Test Loss: 0.0045, Duration: 0:00:00.026066\n",
      "Epoch 1401/1500, Train Loss: 0.0045,       Test Loss: 0.0041, Duration: 0:00:00.026616\n",
      "Epoch 1402/1500, Train Loss: 0.0045,       Test Loss: 0.0041, Duration: 0:00:00.025959\n",
      "Epoch 1403/1500, Train Loss: 0.0048,       Test Loss: 0.0054, Duration: 0:00:00.026084\n",
      "Epoch 1404/1500, Train Loss: 0.0054,       Test Loss: 0.0063, Duration: 0:00:00.025839\n",
      "Epoch 1405/1500, Train Loss: 0.0064,       Test Loss: 0.0076, Duration: 0:00:00.026202\n",
      "Epoch 1406/1500, Train Loss: 0.0072,       Test Loss: 0.0076, Duration: 0:00:00.026676\n",
      "Epoch 1407/1500, Train Loss: 0.0061,       Test Loss: 0.0070, Duration: 0:00:00.027638\n",
      "Epoch 1408/1500, Train Loss: 0.0058,       Test Loss: 0.0058, Duration: 0:00:00.026128\n",
      "Epoch 1409/1500, Train Loss: 0.0052,       Test Loss: 0.0050, Duration: 0:00:00.026295\n",
      "Epoch 1410/1500, Train Loss: 0.0049,       Test Loss: 0.0043, Duration: 0:00:00.027002\n",
      "Epoch 1411/1500, Train Loss: 0.0045,       Test Loss: 0.0043, Duration: 0:00:00.026046\n",
      "Epoch 1412/1500, Train Loss: 0.0047,       Test Loss: 0.0041, Duration: 0:00:00.025917\n",
      "Epoch 1413/1500, Train Loss: 0.0046,       Test Loss: 0.0037, Duration: 0:00:00.026093\n",
      "Epoch 1414/1500, Train Loss: 0.0043,       Test Loss: 0.0035, Duration: 0:00:00.026670\n",
      "Epoch 1415/1500, Train Loss: 0.0043,       Test Loss: 0.0037, Duration: 0:00:00.027241\n",
      "Epoch 1416/1500, Train Loss: 0.0042,       Test Loss: 0.0041, Duration: 0:00:00.026278\n",
      "Epoch 1417/1500, Train Loss: 0.0043,       Test Loss: 0.0048, Duration: 0:00:00.025991\n",
      "Epoch 1418/1500, Train Loss: 0.0053,       Test Loss: 0.0049, Duration: 0:00:00.026374\n",
      "Epoch 1419/1500, Train Loss: 0.0048,       Test Loss: 0.0043, Duration: 0:00:00.025871\n",
      "Epoch 1420/1500, Train Loss: 0.0045,       Test Loss: 0.0043, Duration: 0:00:00.025838\n",
      "Epoch 1421/1500, Train Loss: 0.0044,       Test Loss: 0.0042, Duration: 0:00:00.025688\n",
      "Epoch 1422/1500, Train Loss: 0.0045,       Test Loss: 0.0041, Duration: 0:00:00.026943\n",
      "Epoch 1423/1500, Train Loss: 0.0048,       Test Loss: 0.0050, Duration: 0:00:00.026768\n",
      "Epoch 1424/1500, Train Loss: 0.0044,       Test Loss: 0.0037, Duration: 0:00:00.026426\n",
      "Epoch 1425/1500, Train Loss: 0.0042,       Test Loss: 0.0042, Duration: 0:00:00.026096\n",
      "Epoch 1426/1500, Train Loss: 0.0045,       Test Loss: 0.0048, Duration: 0:00:00.026238\n",
      "Epoch 1427/1500, Train Loss: 0.0044,       Test Loss: 0.0036, Duration: 0:00:00.025843\n",
      "Epoch 1428/1500, Train Loss: 0.0042,       Test Loss: 0.0039, Duration: 0:00:00.026156\n",
      "Epoch 1429/1500, Train Loss: 0.0047,       Test Loss: 0.0049, Duration: 0:00:00.026730\n",
      "Epoch 1430/1500, Train Loss: 0.0049,       Test Loss: 0.0055, Duration: 0:00:00.026789\n",
      "Epoch 1431/1500, Train Loss: 0.0055,       Test Loss: 0.0061, Duration: 0:00:00.027416\n",
      "Epoch 1432/1500, Train Loss: 0.0059,       Test Loss: 0.0076, Duration: 0:00:00.026175\n",
      "Epoch 1433/1500, Train Loss: 0.0060,       Test Loss: 0.0067, Duration: 0:00:00.026246\n",
      "Epoch 1434/1500, Train Loss: 0.0067,       Test Loss: 0.0083, Duration: 0:00:00.025946\n",
      "Epoch 1435/1500, Train Loss: 0.0068,       Test Loss: 0.0071, Duration: 0:00:00.025672\n",
      "Epoch 1436/1500, Train Loss: 0.0060,       Test Loss: 0.0054, Duration: 0:00:00.025653\n",
      "Epoch 1437/1500, Train Loss: 0.0052,       Test Loss: 0.0055, Duration: 0:00:00.025627\n",
      "Epoch 1438/1500, Train Loss: 0.0051,       Test Loss: 0.0065, Duration: 0:00:00.026637\n",
      "Epoch 1439/1500, Train Loss: 0.0057,       Test Loss: 0.0063, Duration: 0:00:00.026675\n",
      "Epoch 1440/1500, Train Loss: 0.0055,       Test Loss: 0.0051, Duration: 0:00:00.026867\n",
      "Epoch 1441/1500, Train Loss: 0.0051,       Test Loss: 0.0057, Duration: 0:00:00.026301\n",
      "Epoch 1442/1500, Train Loss: 0.0051,       Test Loss: 0.0058, Duration: 0:00:00.026070\n",
      "Epoch 1443/1500, Train Loss: 0.0052,       Test Loss: 0.0050, Duration: 0:00:00.026150\n",
      "Epoch 1444/1500, Train Loss: 0.0053,       Test Loss: 0.0053, Duration: 0:00:00.025795\n",
      "Epoch 1445/1500, Train Loss: 0.0052,       Test Loss: 0.0056, Duration: 0:00:00.026216\n",
      "Epoch 1446/1500, Train Loss: 0.0050,       Test Loss: 0.0050, Duration: 0:00:00.026434\n",
      "Epoch 1447/1500, Train Loss: 0.0051,       Test Loss: 0.0048, Duration: 0:00:00.027000\n",
      "Epoch 1448/1500, Train Loss: 0.0050,       Test Loss: 0.0049, Duration: 0:00:00.027022\n",
      "Epoch 1449/1500, Train Loss: 0.0052,       Test Loss: 0.0045, Duration: 0:00:00.026184\n",
      "Epoch 1450/1500, Train Loss: 0.0050,       Test Loss: 0.0052, Duration: 0:00:00.026474\n",
      "Epoch 1451/1500, Train Loss: 0.0052,       Test Loss: 0.0062, Duration: 0:00:00.026068\n",
      "Epoch 1452/1500, Train Loss: 0.0061,       Test Loss: 0.0056, Duration: 0:00:00.025892\n",
      "Epoch 1453/1500, Train Loss: 0.0057,       Test Loss: 0.0066, Duration: 0:00:00.026110\n",
      "Epoch 1454/1500, Train Loss: 0.0064,       Test Loss: 0.0067, Duration: 0:00:00.026918\n",
      "Epoch 1455/1500, Train Loss: 0.0059,       Test Loss: 0.0062, Duration: 0:00:00.027202\n",
      "Epoch 1456/1500, Train Loss: 0.0058,       Test Loss: 0.0064, Duration: 0:00:00.026356\n",
      "Epoch 1457/1500, Train Loss: 0.0053,       Test Loss: 0.0054, Duration: 0:00:00.025599\n",
      "Epoch 1458/1500, Train Loss: 0.0057,       Test Loss: 0.0089, Duration: 0:00:00.026283\n",
      "Epoch 1459/1500, Train Loss: 0.0069,       Test Loss: 0.0078, Duration: 0:00:00.025908\n",
      "Epoch 1460/1500, Train Loss: 0.0074,       Test Loss: 0.0079, Duration: 0:00:00.025714\n",
      "Epoch 1461/1500, Train Loss: 0.0058,       Test Loss: 0.0052, Duration: 0:00:00.025571\n",
      "Epoch 1462/1500, Train Loss: 0.0050,       Test Loss: 0.0059, Duration: 0:00:00.026443\n",
      "Epoch 1463/1500, Train Loss: 0.0054,       Test Loss: 0.0053, Duration: 0:00:00.027425\n",
      "Epoch 1464/1500, Train Loss: 0.0055,       Test Loss: 0.0052, Duration: 0:00:00.027032\n",
      "Epoch 1465/1500, Train Loss: 0.0050,       Test Loss: 0.0054, Duration: 0:00:00.025663\n",
      "Epoch 1466/1500, Train Loss: 0.0052,       Test Loss: 0.0062, Duration: 0:00:00.026185\n",
      "Epoch 1467/1500, Train Loss: 0.0055,       Test Loss: 0.0067, Duration: 0:00:00.026840\n",
      "Epoch 1468/1500, Train Loss: 0.0060,       Test Loss: 0.0065, Duration: 0:00:00.026093\n",
      "Epoch 1469/1500, Train Loss: 0.0052,       Test Loss: 0.0042, Duration: 0:00:00.026035\n",
      "Epoch 1470/1500, Train Loss: 0.0045,       Test Loss: 0.0053, Duration: 0:00:00.026519\n",
      "Epoch 1471/1500, Train Loss: 0.0052,       Test Loss: 0.0053, Duration: 0:00:00.027520\n",
      "Epoch 1472/1500, Train Loss: 0.0058,       Test Loss: 0.0072, Duration: 0:00:00.026033\n",
      "Epoch 1473/1500, Train Loss: 0.0061,       Test Loss: 0.0061, Duration: 0:00:00.026131\n",
      "Epoch 1474/1500, Train Loss: 0.0053,       Test Loss: 0.0058, Duration: 0:00:00.025742\n",
      "Epoch 1475/1500, Train Loss: 0.0052,       Test Loss: 0.0055, Duration: 0:00:00.026118\n",
      "Epoch 1476/1500, Train Loss: 0.0053,       Test Loss: 0.0058, Duration: 0:00:00.025779\n",
      "Epoch 1477/1500, Train Loss: 0.0054,       Test Loss: 0.0058, Duration: 0:00:00.026209\n",
      "Epoch 1478/1500, Train Loss: 0.0059,       Test Loss: 0.0066, Duration: 0:00:00.026523\n",
      "Epoch 1479/1500, Train Loss: 0.0054,       Test Loss: 0.0054, Duration: 0:00:00.027569\n",
      "Epoch 1480/1500, Train Loss: 0.0050,       Test Loss: 0.0060, Duration: 0:00:00.026269\n",
      "Epoch 1481/1500, Train Loss: 0.0058,       Test Loss: 0.0055, Duration: 0:00:00.026278\n",
      "Epoch 1482/1500, Train Loss: 0.0056,       Test Loss: 0.0058, Duration: 0:00:00.026154\n",
      "Epoch 1483/1500, Train Loss: 0.0056,       Test Loss: 0.0059, Duration: 0:00:00.025962\n",
      "Epoch 1484/1500, Train Loss: 0.0054,       Test Loss: 0.0046, Duration: 0:00:00.025757\n",
      "Epoch 1485/1500, Train Loss: 0.0047,       Test Loss: 0.0040, Duration: 0:00:00.026217\n",
      "Epoch 1486/1500, Train Loss: 0.0046,       Test Loss: 0.0039, Duration: 0:00:00.027544\n",
      "Epoch 1487/1500, Train Loss: 0.0044,       Test Loss: 0.0040, Duration: 0:00:00.027379\n",
      "Epoch 1488/1500, Train Loss: 0.0045,       Test Loss: 0.0048, Duration: 0:00:00.026195\n",
      "Epoch 1489/1500, Train Loss: 0.0047,       Test Loss: 0.0049, Duration: 0:00:00.025964\n",
      "Epoch 1490/1500, Train Loss: 0.0050,       Test Loss: 0.0049, Duration: 0:00:00.026139\n",
      "Epoch 1491/1500, Train Loss: 0.0049,       Test Loss: 0.0046, Duration: 0:00:00.025922\n",
      "Epoch 1492/1500, Train Loss: 0.0050,       Test Loss: 0.0049, Duration: 0:00:00.026041\n",
      "Epoch 1493/1500, Train Loss: 0.0051,       Test Loss: 0.0054, Duration: 0:00:00.025858\n",
      "Epoch 1494/1500, Train Loss: 0.0068,       Test Loss: 0.0094, Duration: 0:00:00.026952\n",
      "Epoch 1495/1500, Train Loss: 0.0082,       Test Loss: 0.0092, Duration: 0:00:00.027269\n",
      "Epoch 1496/1500, Train Loss: 0.0071,       Test Loss: 0.0061, Duration: 0:00:00.026643\n",
      "Epoch 1497/1500, Train Loss: 0.0058,       Test Loss: 0.0051, Duration: 0:00:00.026018\n",
      "Epoch 1498/1500, Train Loss: 0.0055,       Test Loss: 0.0052, Duration: 0:00:00.025966\n",
      "Epoch 1499/1500, Train Loss: 0.0055,       Test Loss: 0.0052, Duration: 0:00:00.025789\n",
      "Epoch 1500/1500, Train Loss: 0.0048,       Test Loss: 0.0039, Duration: 0:00:00.025885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stuff to store\n",
    "train_losses = np.zeros(epochs)\n",
    "test_losses = np.zeros(epochs)\n",
    "best_loss = 1e9\n",
    "for it in range(epochs):\n",
    "# zero the parameter gradients\n",
    "    model.train()\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss = []\n",
    "\n",
    "    for inputs, targets in iter(train_loader):\n",
    "    # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss.append(loss.item())\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_losses[it] = train_loss\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    for inputs, targets in iter(test_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_losses[it] = test_loss\n",
    "\n",
    "# Save losses\n",
    "    dt = datetime.now() - t0\n",
    "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        #torch.save(model.state_dict(), best_model)\n",
    "        best_loss = test_loss\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.702315Z",
     "start_time": "2024-02-21T08:27:40.007109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.791680Z",
     "start_time": "2024-02-21T08:28:19.703201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.5298,  0.5298, -0.2528]]), tensor([[-1.0000, -0.7778,  0.5556]]))\n",
      "tensor([[-1.0245, -0.7650,  0.5219]], grad_fn=<AddmmBackward0>)\n",
      "predicted [[-92.20646  -68.8463    46.974804]]\n",
      "actual [[-90.       -70.        50.000004]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "sample = dataset[50]\n",
    "output = model.forward(sample[0])\n",
    "print(sample)\n",
    "print(output)\n",
    "print('predicted', output.detach().numpy()*90)\n",
    "print('actual', sample[1].detach().numpy()*90)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.796886Z",
     "start_time": "2024-02-21T08:28:19.793354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.14875857 36.55266804 -2.22222222] [48.79383234 61.68878012 28.19638266] [126.1  148.71  39.39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.means, dataset.stds, dataset.maxs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.801085Z",
     "start_time": "2024-02-21T08:28:19.798702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43709233 0.        ]]\n",
      "tensor([[0.0000, 0.4371, 0.0000]])\n",
      "[[0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "means = dataset.means\n",
    "stds = dataset.stds\n",
    "maxs = dataset.maxs\n",
    "x = np.array([[0,65,0]])\n",
    "x = Dataset.normalize(x,means,stds,maxs)\n",
    "print(x)\n",
    "input = torch.from_numpy(x.astype(np.float32))\n",
    "output = model.forward(input).detach().numpy()*90\n",
    "print(input)\n",
    "print(np.floor(output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.807998Z",
     "start_time": "2024-02-21T08:28:19.805049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/Users/kevywilly/Projects/vecna/best_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:58.915043Z",
     "start_time": "2024-02-21T08:28:58.908532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:28:19.826515Z",
     "start_time": "2024-02-21T08:28:19.812691Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
